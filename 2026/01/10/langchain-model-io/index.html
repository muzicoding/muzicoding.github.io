<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>LangChain使用之Model I/O | MuziCoding</title><meta name="author" content="Muzi"><meta name="copyright" content="Muzi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="1. Model I&#x2F;O介绍Model I&#x2F;O 模块是与语言模型（LLMs）进行交互的 核心组件 ，在整个框架中有着很重要的地位。 所谓的Model I&#x2F;O，包括输入提示(Format)、调用模型(Predict)、输出解析(Parse)。分别对应着Prompt Template ， Model 和 Output Parser 。 2. Model I&#x2F;O之">
<meta property="og:type" content="article">
<meta property="og:title" content="LangChain使用之Model I&#x2F;O">
<meta property="og:url" content="http://example.com/2026/01/10/langchain-model-io/index.html">
<meta property="og:site_name" content="MuziCoding">
<meta property="og:description" content="1. Model I&#x2F;O介绍Model I&#x2F;O 模块是与语言模型（LLMs）进行交互的 核心组件 ，在整个框架中有着很重要的地位。 所谓的Model I&#x2F;O，包括输入提示(Format)、调用模型(Predict)、输出解析(Parse)。分别对应着Prompt Template ， Model 和 Output Parser 。 2. Model I&#x2F;O之">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://github.com/muzicoding/muzicoding-img/blob/master/avatar/avatar.png?raw=true">
<meta property="article:published_time" content="2026-01-09T16:00:00.000Z">
<meta property="article:modified_time" content="2026-01-10T06:35:08.897Z">
<meta property="article:author" content="Muzi">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="Laingchain">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/muzicoding/muzicoding-img/blob/master/avatar/avatar.png?raw=true"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "LangChain使用之Model I/O",
  "url": "http://example.com/2026/01/10/langchain-model-io/",
  "image": "https://github.com/muzicoding/muzicoding-img/blob/master/avatar/avatar.png?raw=true",
  "datePublished": "2026-01-09T16:00:00.000Z",
  "dateModified": "2026-01-10T06:35:08.897Z",
  "author": [
    {
      "@type": "Person",
      "name": "Muzi",
      "url": "http://example.com"
    }
  ]
}</script><link rel="shortcut icon" href="https://github.com/muzicoding/muzicoding-img/blob/master/favicon/favicon-32x32.png?raw=true"><link rel="canonical" href="http://example.com/2026/01/10/langchain-model-io/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.3"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LangChain使用之Model I/O',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"></head><body><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://github.com/muzicoding/muzicoding-img/blob/master/footer_img/background.jpeg?raw=true);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="https://github.com/muzicoding/muzicoding-img/blob/master/favicon/favicon-32x32.png?raw=true" alt="Logo"><span class="site-name">MuziCoding</span></a><a class="nav-page-title" href="/"><span class="site-name">LangChain使用之Model I/O</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">LangChain使用之Model I/O</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2026-01-09T16:00:00.000Z" title="发表于 2026-01-10 00:00:00">2026-01-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-01-10T06:35:08.897Z" title="更新于 2026-01-10 14:35:08">2026-01-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/LLM/">LLM</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="1-Model-I-O介绍"><a href="#1-Model-I-O介绍" class="headerlink" title="1. Model I&#x2F;O介绍"></a>1. Model I&#x2F;O介绍</h2><p>Model I&#x2F;O 模块是与语言模型（LLMs）进行交互的 核心组件 ，在整个框架中有着很重要的地位。</p>
<p>所谓的Model I&#x2F;O，包括输入提示(Format)、调用模型(Predict)、输出解析(Parse)。分别对应着<br>Prompt Template ， Model 和 Output Parser 。</p>
<h2 id="2-Model-I-O之调用模型1"><a href="#2-Model-I-O之调用模型1" class="headerlink" title="2. Model I&#x2F;O之调用模型1"></a>2. Model I&#x2F;O之调用模型1</h2><h3 id="2-1-LLMs-非对话模型"><a href="#2-1-LLMs-非对话模型" class="headerlink" title="2.1 LLMs(非对话模型)"></a>2.1 LLMs(非对话模型)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> OllamaLLM</span><br><span class="line"></span><br><span class="line"><span class="comment">###########核心代码############</span></span><br><span class="line">llm = OllamaLLM(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line"><span class="built_in">str</span> = llm.invoke(<span class="string">&quot;写一首关于春天的诗&quot;</span>) <span class="comment"># 直接输入字符串</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">str</span>)</span><br></pre></td></tr></table></figure>

<pre><code>春光熹微生绿意，
万物复苏展新姿。
柳条摇曳，如舞者轻盈，
桃花笑靥，似佳人醉人。

风儿温柔，带走了冬日的寒冷，
溪水潺潺，唤醒了大地的生机。

春天啊，你是一首无尽的诗，
在每个角落，都留下了你的足迹。
</code></pre>
<h3 id="2-2-Chat-Models-对话模型"><a href="#2-2-Chat-Models-对话模型" class="headerlink" title="2.2 Chat Models(对话模型)"></a>2.2 Chat Models(对话模型)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage, HumanMessage</span><br><span class="line"></span><br><span class="line"><span class="comment">########核心代码############</span></span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line">messages = [</span><br><span class="line">SystemMessage(content=<span class="string">&quot;我是人工智能助手，我叫小智&quot;</span>),</span><br><span class="line">HumanMessage(content=<span class="string">&quot;你好，我是小明，很高兴认识你&quot;</span>)</span><br><span class="line">]</span><br><span class="line">response = chat_model.invoke(messages) <span class="comment"># 输入消息列表</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response)) <span class="comment"># &lt;class &#x27;langchain_core.messages.ai.AIMessage&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;langchain_core.messages.ai.AIMessage&#39;&gt;
你好，小明！我也很高兴能和你相识。有什么我能帮助你的吗？
</code></pre>
<h3 id="2-3-Embedding-Model-嵌入模型"><a href="#2-3-Embedding-Model-嵌入模型" class="headerlink" title="2.3 Embedding Model(嵌入模型)"></a>2.3 Embedding Model(嵌入模型)</h3><p>也叫文本嵌入模型，这些模型将 文本 作为输入并返回 浮点数列表 ，也就是Embedding。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_huggingface <span class="keyword">import</span> HuggingFaceEmbeddings</span><br><span class="line">embeddings_model = HuggingFaceEmbeddings(model_name=<span class="string">&quot;all-MiniLM-L6-v2&quot;</span>)</span><br><span class="line"></span><br><span class="line">res1 = embeddings_model.embed_query(<span class="string">&#x27;我是文档中的数据&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(res1)</span><br></pre></td></tr></table></figure>

<pre><code>[-0.005971120670437813, 0.1181352436542511, 0.0830983817577362, 0.011212742887437344, 0.02068527415394783, 0.06367464363574982, 0.12943081557750702, -0.01952940970659256, 0.09395983815193176, -0.01008662674576044, 0.07168331742286682, -0.0617380291223526, -0.006280721165239811, -0.0618385374546051, -0.0038902126252651215, -0.00376925733871758, -0.007139479275792837, 0.018814895302057266, -0.08897339552640915, 0.04855788126587868, 0.003366539254784584, 0.0005220387247391045, 0.03224669769406319, 0.03269338235259056, -0.02435752935707569, -0.008826270699501038, -0.06456027179956436, 0.030281925573945045, 0.07276643812656403, -0.016566898673772812, -0.0611230805516243, 0.027421796694397926, 0.029109766706824303, 0.045004263520240784, 0.02511175163090229, -0.011827034875750542, -0.06430739164352417, -0.06335082650184631, -0.0023616475518792868, 0.039809659123420715, 0.017913194373250008, 0.014017906039953232, 0.05884871259331703, -0.05516044422984123, -0.02203972265124321, -0.0031187806744128466, -0.036344125866889954, 0.024495556950569153, 0.009633239358663559, -0.008592814207077026, -0.06927768141031265, 0.010904612019658089, -0.026483487337827682, -0.013838136568665504, 0.04537161812186241, 0.05904877185821533, 0.00021336115605663508, 0.011700798757374287, 0.022003956139087677, -0.08415704220533371, -0.048397570848464966, -0.0041738892905414104, 0.005075054243206978, 0.0019025597721338272, 0.0372481495141983, 0.0019538062624633312, -0.0484994538128376, -0.012731919065117836, -0.0153339933604002, 0.034182485193014145, -0.0573759526014328, 0.012676979415118694, -0.05078371241688728, 0.008626093156635761, -0.03519042208790779, -0.017050715163350105, 0.019081486389040947, 0.00803819764405489, -0.008852358907461166, -0.04535198584198952, -0.001983050489798188, -0.034420762211084366, -0.01852131262421608, 0.046186383813619614, 0.013133850879967213, 0.0073355939239263535, -0.052305079996585846, 0.04377488046884537, -0.03953789919614792, 0.03018755465745926, -0.021876689046621323, 0.06704337149858475, -0.02806314267218113, 0.0356590561568737, -0.19870525598526, 0.04366826266050339, -0.019544778391718864, -0.07817289233207703, 0.0083957863971591, -0.012037429958581924, 0.05443844199180603, 0.07449425011873245, 0.035464052110910416, -0.00034444627817720175, -0.019804146140813828, -0.08412270247936249, -0.03370565176010132, 0.0025945210363715887, 0.045589618384838104, -0.04397839307785034, -0.025102244690060616, -0.06580039113759995, -0.09575039148330688, -0.05118337273597717, 0.03346183896064758, 0.03725109621882439, 0.029276560992002487, 0.009301532059907913, -0.025361523032188416, 0.0013745358446612954, -0.024846315383911133, -0.033091697841882706, -0.1100616306066513, -0.10615135729312897, -0.09644815325737, -0.12655556201934814, 0.05763690546154976, 1.0103825775958658e-33, -0.017396526411175728, -0.020177332684397697, 0.044400423765182495, -0.028673049062490463, -0.008271484635770321, -0.05824282765388489, 0.07832539081573486, 0.008700150065124035, -0.1032075509428978, -0.03020401857793331, -0.007500675041228533, 0.0019345948239788413, -0.03575584664940834, -0.020620036870241165, -0.035797107964754105, 0.048083193600177765, -0.006303754635155201, -0.048131853342056274, 0.09648478776216507, -0.004449681378901005, 0.0508279912173748, -0.055282361805438995, 0.0005450717872008681, -0.0012410455383360386, 0.06659416109323502, -0.0747150406241417, 0.07340662181377411, -0.01983363926410675, -0.01657397858798504, 0.007246384397149086, -0.009850816801190376, 0.010764796286821365, 0.00014820425712969154, -0.04214266687631607, -0.026951581239700317, 0.00023030971351545304, 0.0656074732542038, 0.10191597044467926, 0.049417685717344284, 0.02774137444794178, 0.039513472467660904, -0.06394200772047043, -0.03375605493783951, -0.08516838401556015, 0.02628987468779087, 0.047433704137802124, 0.004862336907535791, -0.07494115084409714, 0.02824551798403263, -0.012263599783182144, 0.04635874927043915, -0.024724984541535378, -0.043663132935762405, 0.08003256469964981, 0.0865674689412117, -0.01923336647450924, -0.012349461205303669, 0.024238569661974907, -0.09720785915851593, -0.04756410792469978, 0.05620012804865837, -0.13646528124809265, -0.06551308184862137, 0.05072912573814392, -0.016747908666729927, -0.007960069924592972, 0.020861176773905754, -0.07167943567037582, 0.014741727150976658, -0.06303147226572037, -0.1154789850115776, -0.019842425361275673, 0.13785256445407867, -0.022096039727330208, -0.06435603648424149, 0.025453008711338043, -0.12617790699005127, 0.00029712339164689183, 0.05586498975753784, 0.03537161275744438, -0.08415637910366058, -0.045454274863004684, -0.007046065758913755, 0.04844594746828079, 0.025758342817425728, 0.023656049743294716, 0.02483317442238331, 0.02370039001107216, 0.04056745022535324, 0.08242295682430267, -0.0988667830824852, -0.0611952506005764, 0.08825087547302246, -0.015301808714866638, -0.10192426294088364, -3.487721860932467e-33, 0.0017665220657363534, 0.1200307235121727, -0.04029503092169762, -0.01893990859389305, -0.015716176480054855, 0.026711152866482735, 0.054180946201086044, 0.10329963266849518, -0.02154715545475483, 0.021801983937621117, 0.023338040336966515, -0.05293058976531029, 0.06831002980470657, 0.06534536182880402, 0.016211966052651405, 0.08052721619606018, 0.030668945983052254, 0.0554615817964077, -0.06759601086378098, 0.041708823293447495, -0.01879742741584778, -0.04255497455596924, -0.0008367004338651896, 0.02417852357029915, 0.014168748632073402, -0.0028968339320272207, 0.09429111331701279, -0.060520321130752563, 0.032173383980989456, -0.028590243309736252, -0.0187238696962595, -0.0039924196898937225, -0.06387349218130112, 0.11089722067117691, -0.029475759714841843, -0.07946034520864487, 0.006403553299605846, -0.11070951819419861, -0.0158221498131752, 0.10187841206789017, 0.039515942335128784, 0.013113614171743393, 0.02725684456527233, 0.030874034389853477, 0.020334595814347267, 0.02771291323006153, -0.06374796479940414, -0.07086994498968124, -0.040423884987831116, 0.09352076053619385, 0.04115598648786545, -0.00631296681240201, 0.02680269628763199, -0.0487014576792717, 0.014458613470196724, 0.060343775898218155, 0.07612854242324829, -0.025013860315084457, -0.020288962870836258, -0.03204924985766411, -0.055547598749399185, 0.0770491287112236, -0.06297030299901962, -0.04283878207206726, -0.006151476409286261, 0.028528820723295212, 0.030592428520321846, 0.046493351459503174, 0.019259365275502205, -0.03808651864528656, 0.09871861338615417, 0.0073605184443295, -0.04065011441707611, -0.015575442463159561, -0.1267157793045044, 0.02696782909333706, 0.011770043522119522, 0.0563366673886776, 0.02238820493221283, 0.06273981183767319, 0.050988730043172836, 0.022845521569252014, 0.0025717210955917835, -0.06615062803030014, -0.0066059185191988945, -0.005716494284570217, -0.033691421151161194, 0.040644437074661255, -0.06328555941581726, -0.02554008737206459, -0.02980422042310238, 0.009894279763102531, 0.0464249923825264, -0.01740059070289135, 0.004021218977868557, -1.7555239040234483e-08, -0.07538563013076782, -0.09727001190185547, -0.002578080864623189, -0.0638776570558548, 0.020289765670895576, 0.028700243681669235, -0.018171697854995728, 0.06376081705093384, 0.03499815985560417, -0.037470653653144836, 0.08891736716032028, -0.03862800821661949, -0.08219578862190247, 0.054910287261009216, -0.051475655287504196, 0.01753133162856102, -0.042804617434740067, -0.03886469826102257, 0.04138392210006714, -0.07266197353601456, 0.022552531212568283, 0.017061633989214897, -0.04348111152648926, 0.011939914897084236, -0.031883031129837036, 0.05215625464916229, -0.06570058315992355, -0.009399283677339554, -0.06640693545341492, 0.048683226108551025, 0.002287500537931919, 0.020385609939694405, 0.024010511115193367, 0.03683938458561897, 0.014285082928836346, -0.028004156425595284, 0.044589005410671234, -0.02856755070388317, 0.07183156907558441, 0.05738396197557449, 0.05999979004263878, 0.020402520895004272, 0.004054602235555649, 0.03925320878624916, 0.0761069804430008, -0.05611884593963623, 0.05090487003326416, -0.030141320079565048, 0.017083289101719856, -0.015395102091133595, -0.03366788849234581, 0.0010483835358172655, 0.031286854296922684, -0.043768271803855896, -0.05992356687784195, 0.11699484288692474, 0.004732421133667231, 0.05098041519522667, 0.023034095764160156, 0.026949042454361916, 0.03608988597989082, 0.10980959981679916, -0.003774048062041402, -0.050992678850889206]
</code></pre>
<h2 id="3-Model-I-O之调用模型2"><a href="#3-Model-I-O之调用模型2" class="headerlink" title="3. Model I&#x2F;O之调用模型2"></a>3. Model I&#x2F;O之调用模型2</h2><h3 id="3-1-关于对话模型的Message-消息"><a href="#3-1-关于对话模型的Message-消息" class="headerlink" title="3.1 关于对话模型的Message(消息)"></a>3.1 关于对话模型的Message(消息)</h3><p>聊天模型，出了将字符串作为输入外，还可以使用 聊天消息 作为输入，并返回 聊天消息 作为输出。</p>
<p>LangChain有一些内置的消息类型：</p>
<ul>
<li><code>SystemMessage</code> ：设定AI行为规则或背景信息。比如设定AI的初始状态、行为模式或对话的总体目标。比如“作为一个代码专家”，或者“返回json格式”。通常作为输入消息序列中的第一个<br>传递。</li>
<li><code>HumanMessage</code> ：表示来自用户输入。比如“实现 一个快速排序方法”</li>
<li><code>AIMessage</code> ：存储AI回复的内容。这可以是文本，也可以是调用工具的请求</li>
<li><code>ChatMessage</code> ：可以自定义角色的通用消息类型</li>
<li><code>FunctionMessage/ToolMessage</code> ：函数调用&#x2F;工具消息，用于函数调用结果的消息类型</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子1</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage, HumanMessage</span><br><span class="line">messages = [</span><br><span class="line">    SystemMessage(content=<span class="string">&quot;我是人工智能助手，我叫小智&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;你好，我是小明，很高兴认识你&quot;</span>)</span><br><span class="line">]</span><br><span class="line"><span class="built_in">print</span>(messages)</span><br></pre></td></tr></table></figure>

<pre><code>[SystemMessage(content=&#39;我是人工智能助手，我叫小智&#39;, additional_kwargs={}, response_metadata={}), HumanMessage(content=&#39;你好，我是小明，很高兴认识你&#39;, additional_kwargs={}, response_metadata={})]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子2</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage, AIMessage, HumanMessage</span><br><span class="line"></span><br><span class="line">messages = [</span><br><span class="line">    SystemMessage(content=[<span class="string">&quot;你是一个数学家,只会回答数学问题&quot;</span>,<span class="string">&quot;每次你都能给出详细的方案&quot;</span>]),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;1 + 2 * 3 = ?&quot;</span>),</span><br><span class="line">    AIMessage(content=<span class="string">&quot;1 + 2 * 3 的结果是7&quot;</span>)</span><br><span class="line">]</span><br><span class="line"><span class="built_in">print</span>(messages)</span><br></pre></td></tr></table></figure>

<pre><code>[SystemMessage(content=[&#39;你是一个数学家,只会回答数学问题&#39;, &#39;每次你都能给出详细的方案&#39;], additional_kwargs={}, response_metadata={}), HumanMessage(content=&#39;1 + 2 * 3 = ?&#39;, additional_kwargs={}, response_metadata={}), AIMessage(content=&#39;1 + 2 * 3 的结果是7&#39;, additional_kwargs={}, response_metadata={})]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子3</span></span><br><span class="line"><span class="comment">#1.导入相关包</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage, HumanMessage, AIMessage</span><br><span class="line"><span class="comment"># 2.直接创建不同类型消息</span></span><br><span class="line">systemMessage = SystemMessage(</span><br><span class="line">content=<span class="string">&quot;你是一个AI开发工程师&quot;</span>,</span><br><span class="line">additional_kwargs=&#123;<span class="string">&quot;tool&quot;</span>: <span class="string">&quot;invoke_tool()&quot;</span>&#125;</span><br><span class="line">)</span><br><span class="line">humanMessage = HumanMessage(</span><br><span class="line">content=<span class="string">&quot;你能开发哪些AI应用?&quot;</span></span><br><span class="line">)</span><br><span class="line">aiMessage = AIMessage(</span><br><span class="line">content=<span class="string">&quot;我能开发很多AI应用, 比如聊天机器人, 图像识别, 自然语言处理等&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 3.打印消息列表</span></span><br><span class="line">messages = [systemMessage,humanMessage,aiMessage]</span><br><span class="line"><span class="built_in">print</span>(messages)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>[SystemMessage(content=&#39;你是一个AI开发工程师&#39;, additional_kwargs={&#39;你的名字&#39;: &#39;MuziAI&#39;}, response_metadata={}), HumanMessage(content=&#39;你能开发哪些AI应用?&#39;, additional_kwargs={}, response_metadata={}), AIMessage(content=&#39;我能开发很多AI应用, 比如聊天机器人, 图像识别, 自然语言处理等&#39;, additional_kwargs={}, response_metadata={})]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子4</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> (</span><br><span class="line">AIMessage,</span><br><span class="line">HumanMessage,</span><br><span class="line">SystemMessage,</span><br><span class="line">ChatMessage</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建不同类型的消息</span></span><br><span class="line">system_message = SystemMessage(content=<span class="string">&quot;你是一个专业的数据科学家&quot;</span>)</span><br><span class="line">human_message = HumanMessage(content=<span class="string">&quot;解释一下随机森林算法&quot;</span>)</span><br><span class="line">ai_message = AIMessage(content=<span class="string">&quot;随机森林是一种集成学习方法...&quot;</span>)</span><br><span class="line">custom_message = ChatMessage(role=<span class="string">&quot;analyst&quot;</span>, content=<span class="string">&quot;补充一点关于超参数调优的信息&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(system_message.content)</span><br><span class="line"><span class="built_in">print</span>(human_message.content)</span><br><span class="line"><span class="built_in">print</span>(ai_message.content)</span><br><span class="line"><span class="built_in">print</span>(custom_message.content)</span><br></pre></td></tr></table></figure>

<pre><code>你是一个专业的数据科学家
解释一下随机森林算法
随机森林是一种集成学习方法...
补充一点关于超参数调优的信息
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子5 结合大模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage,HumanMessage</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line">chat_model = ChatOllama(</span><br><span class="line">    model=<span class="string">&quot;qwen:7b&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 组成消息列表</span></span><br><span class="line">messages = [</span><br><span class="line">    SystemMessage(content=<span class="string">&quot;你是一个擅长人工智能相关学科的专家&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;请解释一下什么是机器学习？&quot;</span>)</span><br><span class="line">]</span><br><span class="line">response = chat_model.invoke(messages)</span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response)) <span class="comment">#&lt;class &#x27;langchain_core.messages.ai.AIMessage&#x27;&gt;</span></span><br></pre></td></tr></table></figure>

<pre><code>机器学习（Machine Learning）是一种计算机科学领域，旨在让计算机系统通过经验自动改善性能，而无需显式编程。

在机器学习中，数据被用于训练模型，这些模型可以对新的、未见过的数据进行预测。常见的机器学习算法包括监督学习（如回归和分类）、无监督学习（如聚类）以及强化学习（侧重于环境交互）等。

总之，机器学习是通过分析大量数据来建立数学模型，进而实现自动化任务的一种人工智能技术。
&lt;class &#39;langchain_core.messages.ai.AIMessage&#39;&gt;
</code></pre>
<h3 id="3-2-关于多轮对话与上下文记忆"><a href="#3-2-关于多轮对话与上下文记忆" class="headerlink" title="3.2 关于多轮对话与上下文记忆"></a>3.2 关于多轮对话与上下文记忆</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取大模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"></span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试1</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage, HumanMessage</span><br><span class="line"></span><br><span class="line">sys_message = SystemMessage(</span><br><span class="line">    content=<span class="string">&quot;我是一个人工智能的助手，我的名字叫小智&quot;</span>,</span><br><span class="line">)</span><br><span class="line">human_message = HumanMessage(content=<span class="string">&quot;猫王是一只猫吗？&quot;</span>)</span><br><span class="line"></span><br><span class="line">messages = [sys_message, human_message]</span><br><span class="line"><span class="comment">#调用大模型，传入messages</span></span><br><span class="line">response = chat_model.invoke(messages)</span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br><span class="line"></span><br><span class="line">response1 = chat_model.invoke(<span class="string">&quot;你叫什么名字？&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response1.content)</span><br></pre></td></tr></table></figure>

<pre><code>不是。&quot;猫王&quot;指的是美国著名的摇滚歌手 Elvis Presley，他的本名是埃尔维斯·普雷斯利。而猫（cat）是一种动物，与这位音乐家无关。
我是来自阿里云的语言模型，我叫通义千问。
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试2</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage, HumanMessage</span><br><span class="line"></span><br><span class="line">sys_message = SystemMessage(</span><br><span class="line">    content=<span class="string">&quot;我是一个人工智能的助手，我的名字叫小智&quot;</span>,</span><br><span class="line">)</span><br><span class="line">human_message = HumanMessage(content=<span class="string">&quot;猫王是一只猫吗？&quot;</span>)</span><br><span class="line">human_message1 = HumanMessage(content=<span class="string">&quot;你叫什么名字？&quot;</span>)</span><br><span class="line"></span><br><span class="line">messages = [sys_message, human_message,human_message1]</span><br><span class="line"><span class="comment">#调用大模型，传入messages</span></span><br><span class="line">response = chat_model.invoke(messages)</span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br></pre></td></tr></table></figure>

<pre><code>我是小智，一个人工智能的助手。关于你的问题，“猫王”通常是指美国流行音乐之王——艾尔维斯·普雷斯利（Elvis Presley），他并不是一只真正的猫。
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试3</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage, HumanMessage</span><br><span class="line"></span><br><span class="line">sys_message = SystemMessage(</span><br><span class="line">    content=<span class="string">&quot;我是一个人工智能的助手，我的名字叫小智&quot;</span>,</span><br><span class="line">)</span><br><span class="line">human_message = HumanMessage(content=<span class="string">&quot;猫王是一只猫吗？&quot;</span>)</span><br><span class="line">sys_message1 = SystemMessage(</span><br><span class="line">    content=<span class="string">&quot;我可以做很多事情，有需要就找我吧&quot;</span>,</span><br><span class="line">)</span><br><span class="line">human_message1 = HumanMessage(content=<span class="string">&quot;你叫什么名字？&quot;</span>)</span><br><span class="line">messages = [sys_message, human_message,sys_message1,human_message1]</span><br><span class="line"><span class="comment">#调用大模型，传入messages</span></span><br><span class="line">response = chat_model.invoke(messages)</span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br></pre></td></tr></table></figure>

<pre><code>我是阿里云推出的一种超大规模语言模型，我叫通义千问。
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试4</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage, HumanMessage</span><br><span class="line"><span class="comment"># 第1组</span></span><br><span class="line">sys_message = SystemMessage(</span><br><span class="line">    content=<span class="string">&quot;我是一个人工智能的助手，我的名字叫小智&quot;</span></span><br><span class="line">)</span><br><span class="line">human_message = HumanMessage(content=<span class="string">&quot;猫王是一只猫吗？&quot;</span>)</span><br><span class="line">messages = [sys_message, human_message]</span><br><span class="line"><span class="comment"># 第2组</span></span><br><span class="line">sys_message1 = SystemMessage(</span><br><span class="line">content=<span class="string">&quot;我可以做很多事情，有需要就找我吧&quot;</span>,</span><br><span class="line">)</span><br><span class="line">human_message1 = HumanMessage(content=<span class="string">&quot;你叫什么名字？&quot;</span>)</span><br><span class="line">messages1 = [sys_message1,human_message1]</span><br><span class="line"><span class="comment">#调用大模型，传入messages</span></span><br><span class="line">response = chat_model.invoke(messages)</span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br><span class="line">response = chat_model.invoke(messages1)</span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br></pre></td></tr></table></figure>

<pre><code>&quot;猫王&quot;（The King of Cats）并不是指一只真正的猫。这是一个常见的昵称或尊称，用于赞誉某个人在特定领域具有卓越才能和影响力，就像猫王埃尔维斯·普雷斯利在音乐界的地位一样。
我是通义千问，由阿里云开发。你可以叫我Qwen。有什么问题我可以帮助你解答吗？
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试5</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage, HumanMessage, AIMessage</span><br><span class="line">messages = [</span><br><span class="line">    SystemMessage(content=<span class="string">&quot;我是一个人工智能助手，我的名字叫小智&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;人工智能英文怎么说？&quot;</span>),</span><br><span class="line">    AIMessage(content=<span class="string">&quot;AI&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;你叫什么名字&quot;</span>)</span><br><span class="line">]</span><br><span class="line">messages1 = [</span><br><span class="line">    SystemMessage(content=<span class="string">&quot;我是一个人工智能助手，我的名字叫小智&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;很高兴认识你&quot;</span>),</span><br><span class="line">    AIMessage(content=<span class="string">&quot;我也很高兴认识你&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;你叫什么名字&quot;</span>)</span><br><span class="line">]</span><br><span class="line">messages2 = [</span><br><span class="line">    SystemMessage(content=<span class="string">&quot;我是一个人工智能助手，我的名字叫小智&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;人工智能英文怎么说？&quot;</span>),</span><br><span class="line">    AIMessage(content=<span class="string">&quot;AI&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;你叫什么名字&quot;</span>)</span><br><span class="line">]</span><br><span class="line">chat_model.invoke(messages2)</span><br></pre></td></tr></table></figure>




<pre><code>AIMessage(content=&#39;我是小智，一个由阿里云研发的人工智能助手。有什么问题或者需要帮助的吗？&#39;, additional_kwargs={}, response_metadata={&#39;model&#39;: &#39;qwen:7b&#39;, &#39;created_at&#39;: &#39;2026-01-05T02:14:09.415996Z&#39;, &#39;done&#39;: True, &#39;done_reason&#39;: &#39;stop&#39;, &#39;total_duration&#39;: 1149513458, &#39;load_duration&#39;: 58478167, &#39;prompt_eval_count&#39;: 39, &#39;prompt_eval_duration&#39;: 112952916, &#39;eval_count&#39;: 23, &#39;eval_duration&#39;: 850694209, &#39;logprobs&#39;: None, &#39;model_name&#39;: &#39;qwen:7b&#39;, &#39;model_provider&#39;: &#39;ollama&#39;}, id=&#39;lc_run--019b8bee-e689-71e3-9fb8-7cf6d1be7fd8-0&#39;, usage_metadata={&#39;input_tokens&#39;: 39, &#39;output_tokens&#39;: 23, &#39;total_tokens&#39;: 62})
</code></pre>
<h3 id="3-3-关于模型调用的方法"><a href="#3-3-关于模型调用的方法" class="headerlink" title="3.3 关于模型调用的方法"></a>3.3 关于模型调用的方法</h3><h4 id="3-3-1-流式输出与非流式输出"><a href="#3-3-1-流式输出与非流式输出" class="headerlink" title="3.3.1 流式输出与非流式输出"></a>3.3.1 流式输出与非流式输出</h4><p><strong>非流式输出</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子1</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="comment">#初始化大模型</span></span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line"><span class="comment"># 创建消息</span></span><br><span class="line">messages = [HumanMessage(content=<span class="string">&quot;你好，请介绍一下自己&quot;</span>)]</span><br><span class="line"><span class="comment"># 非流式调用LLM获取响应</span></span><br><span class="line">response = chat_model.invoke(messages)</span><br><span class="line"><span class="comment"># 打印响应内容</span></span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>

<pre><code>content=&#39;你好！作为一个人工智能模型，我没有传统意义上的个人身份，但我被设计和编程来帮助解答问题、提供信息和服务。\n\n你可以问我任何你想知道的问题，无论是科技知识、历史事件、还是日常生活中的疑惑，我会尽我所能为你提供帮助。&#39; additional_kwargs={} response_metadata={&#39;model&#39;: &#39;qwen:7b&#39;, &#39;created_at&#39;: &#39;2026-01-05T03:29:30.232317Z&#39;, &#39;done&#39;: True, &#39;done_reason&#39;: &#39;stop&#39;, &#39;total_duration&#39;: 25761612100, &#39;load_duration&#39;: 5725023700, &#39;prompt_eval_count&#39;: 13, &#39;prompt_eval_duration&#39;: 1740943200, &#39;eval_count&#39;: 56, &#39;eval_duration&#39;: 18209908000, &#39;logprobs&#39;: None, &#39;model_name&#39;: &#39;qwen:7b&#39;, &#39;model_provider&#39;: &#39;ollama&#39;} id=&#39;lc_run--019b8c33-81d1-74f3-8ecb-e7607d8ccc04-0&#39; usage_metadata={&#39;input_tokens&#39;: 13, &#39;output_tokens&#39;: 56, &#39;total_tokens&#39;: 69}
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子2</span></span><br><span class="line"><span class="comment"># 支持多个消息作为输入</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage</span><br><span class="line">messages = [</span><br><span class="line">SystemMessage(content=<span class="string">&quot;你是一位乐于助人的助手。你叫于老师&quot;</span>),</span><br><span class="line">HumanMessage(content=<span class="string">&quot;你是谁？&quot;</span>)</span><br><span class="line">]</span><br><span class="line">response = chat_model.invoke(messages)</span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br></pre></td></tr></table></figure>

<pre><code>我是于老师，一个虚拟的人工智能助手，专门为大家提供帮助和解答问题。有什么可以帮到你的吗？
</code></pre>
<p><strong>流式输出</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">chat_model = ChatOllama(</span><br><span class="line">    model=<span class="string">&quot;qwen:7b&quot;</span>,</span><br><span class="line">    streaming=<span class="literal">True</span> <span class="comment"># 启用流式输出</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 创建消息</span></span><br><span class="line">messages = [HumanMessage(content=<span class="string">&quot;你好，请介绍一下自己&quot;</span>)]</span><br><span class="line"><span class="comment"># 流式调用LLM获取响应</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;开始流式输出：&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> chat_model.stream(messages):</span><br><span class="line">    <span class="comment"># 逐个打印内容块</span></span><br><span class="line">    <span class="built_in">print</span>(chunk.content, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>) <span class="comment"># 刷新缓冲区 (无换行符，缓冲区未刷新，内容可能不会立即显示)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n流式输出结束&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>开始流式输出：
你好！作为一个人工智能模型，我并没有个人经历可以介绍。但我被设计出来是为了提供帮助和信息的。你可以问我任何问题，我会尽我所能来为你解答。
流式输出结束
</code></pre>
<p><strong>批量调用</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage, SystemMessage</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line">messages1 = [SystemMessage(content=<span class="string">&quot;你是一位乐于助人的智能小助手&quot;</span>),</span><br><span class="line">HumanMessage(content=<span class="string">&quot;请帮我介绍一下什么是机器学习&quot;</span>), ]</span><br><span class="line">messages2 = [SystemMessage(content=<span class="string">&quot;你是一位乐于助人的智能小助手&quot;</span>),</span><br><span class="line">HumanMessage(content=<span class="string">&quot;请帮我介绍一下什么是AIGC&quot;</span>), ]</span><br><span class="line">messages3 = [SystemMessage(content=<span class="string">&quot;你是一位乐于助人的智能小助手&quot;</span>),</span><br><span class="line">HumanMessage(content=<span class="string">&quot;请帮我介绍一下什么是大模型技术&quot;</span>), ]</span><br><span class="line">messages = [messages1, messages2, messages3]</span><br><span class="line"><span class="comment"># 调用batch</span></span><br><span class="line">response = chat_model.batch(messages)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>

<pre><code>[AIMessage(content=&#39;机器学习（Machine Learning，ML）是一门研究计算机如何自动地获取知识并应用到新问题解决中的学科。简单来说，它是指通过让计算机从数据中“学习”模式和规律，而不需要明确的编程规则。\n\n机器学习可以分为监督学习、无监督学习、半监督学习等不同类型。在实际应用中，如自然语言处理（NLP）、图像识别、推荐系统等领域都有大量的机器学习应用。&#39;, additional_kwargs={}, response_metadata={&#39;model&#39;: &#39;qwen:7b&#39;, &#39;created_at&#39;: &#39;2026-01-05T03:42:42.8309294Z&#39;, &#39;done&#39;: True, &#39;done_reason&#39;: &#39;stop&#39;, &#39;total_duration&#39;: 31117442900, &#39;load_duration&#39;: 117861900, &#39;prompt_eval_count&#39;: 27, &#39;prompt_eval_duration&#39;: 4193473600, &#39;eval_count&#39;: 94, &#39;eval_duration&#39;: 26669728200, &#39;logprobs&#39;: None, &#39;model_name&#39;: &#39;qwen:7b&#39;, &#39;model_provider&#39;: &#39;ollama&#39;}, id=&#39;lc_run--019b8c3f-84fd-78c1-9746-99f81b00345e-0&#39;, usage_metadata={&#39;input_tokens&#39;: 27, &#39;output_tokens&#39;: 94, &#39;total_tokens&#39;: 121}), AIMessage(content=&#39;AIGC，全称为Artificial Intelligence General Competition，中文可以理解为“人工智能全能竞赛”或者“人工智能大挑战”。\n\n这个名称通常与举办此类比赛的组织或平台相关。AIGC旨在通过各类AI任务的竞赛，推动人工智能技术的发展，培养更多的AI人才。&#39;, additional_kwargs={}, response_metadata={&#39;model&#39;: &#39;qwen:7b&#39;, &#39;created_at&#39;: &#39;2026-01-05T03:43:30.2706812Z&#39;, &#39;done&#39;: True, &#39;done_reason&#39;: &#39;stop&#39;, &#39;total_duration&#39;: 78554315500, &#39;load_duration&#39;: 130235100, &#39;prompt_eval_count&#39;: 28, &#39;prompt_eval_duration&#39;: 1524710300, &#39;eval_count&#39;: 62, &#39;eval_duration&#39;: 17443658600, &#39;logprobs&#39;: None, &#39;model_name&#39;: &#39;qwen:7b&#39;, &#39;model_provider&#39;: &#39;ollama&#39;}, id=&#39;lc_run--019b8c3f-84ff-7e72-96a5-6a78b5c650c8-0&#39;, usage_metadata={&#39;input_tokens&#39;: 28, &#39;output_tokens&#39;: 62, &#39;total_tokens&#39;: 90}), AIMessage(content=&#39;大模型技术，简单来说，就是指规模较大、参数众多的深度学习模型。这类模型能够处理更复杂的任务，并在大规模数据上进行训练以获得更好的性能。\n\n常见的大模型包括但不限于BERT（Bidirectional Encoder Representations from Transformers）、GPT（Generative Pre-trained Transformer）、U-Net（Unsupervised Image-to-Image Translation）等，它们已在自然语言处理、计算机视觉等多个领域展现出强大的应用潜力。&#39;, additional_kwargs={}, response_metadata={&#39;model&#39;: &#39;qwen:7b&#39;, &#39;created_at&#39;: &#39;2026-01-05T03:43:11.2239618Z&#39;, &#39;done&#39;: True, &#39;done_reason&#39;: &#39;stop&#39;, &#39;total_duration&#39;: 59507712300, &#39;load_duration&#39;: 129186200, &#39;prompt_eval_count&#39;: 28, &#39;prompt_eval_duration&#39;: 1381742200, &#39;eval_count&#39;: 93, &#39;eval_duration&#39;: 26867197000, &#39;logprobs&#39;: None, &#39;model_name&#39;: &#39;qwen:7b&#39;, &#39;model_provider&#39;: &#39;ollama&#39;}, id=&#39;lc_run--019b8c3f-8501-77e0-814d-bff4fb2eb60d-0&#39;, usage_metadata={&#39;input_tokens&#39;: 28, &#39;output_tokens&#39;: 93, &#39;total_tokens&#39;: 121})]
</code></pre>
<h4 id="3-3-3-同步调用与异步调用-了解"><a href="#3-3-3-同步调用与异步调用-了解" class="headerlink" title="3.3.3 同步调用与异步调用(了解)"></a>3.3.3 同步调用与异步调用(了解)</h4><p><strong>同步调用</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call_model</span>():</span><br><span class="line">    <span class="comment"># 模拟同步API调用</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始调用模型...&quot;</span>)</span><br><span class="line">    time.sleep(<span class="number">5</span>) <span class="comment"># 模拟调用等待,单位：秒</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型调用完成。&quot;</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">perform_other_tasks</span>():</span><br><span class="line">    <span class="comment"># 模拟执行其他任务</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;执行其他任务 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">        time.sleep(<span class="number">1</span>) <span class="comment"># 单位：秒</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    call_model()</span><br><span class="line">    perform_other_tasks()</span><br><span class="line">    end_time = time.time()</span><br><span class="line">    total_time = end_time - start_time</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;总共耗时：<span class="subst">&#123;total_time&#125;</span>秒&quot;</span></span><br><span class="line"><span class="comment"># 运行同步任务并打印完成时间</span></span><br><span class="line">main_time = main()</span><br><span class="line"><span class="built_in">print</span>(main_time)</span><br></pre></td></tr></table></figure>

<pre><code>开始调用模型...
模型调用完成。
执行其他任务 1
执行其他任务 2
执行其他任务 3
执行其他任务 4
执行其他任务 5
总共耗时：10.050298690795898秒
</code></pre>
<p><strong>异步调用</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">async_call</span>(<span class="params">llm</span>):</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">5</span>) <span class="comment"># 模拟异步操作</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;异步调用完成&quot;</span>)</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">perform_other_tasks</span>():</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">5</span>) <span class="comment"># 模拟异步操作</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;其他任务完成&quot;</span>)</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">run_async_tasks</span>():</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    <span class="keyword">await</span> asyncio.gather(</span><br><span class="line">        async_call(<span class="literal">None</span>), <span class="comment"># 示例调用，使用None模拟LLM对象</span></span><br><span class="line">        perform_other_tasks()</span><br><span class="line">    )</span><br><span class="line">    end_time = time.time()</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;总共耗时：<span class="subst">&#123;end_time - start_time&#125;</span>秒&quot;</span></span><br><span class="line"><span class="comment"># # 正确运行异步任务的方式</span></span><br><span class="line"><span class="comment"># if __name__ == &quot;__main__&quot;:</span></span><br><span class="line"><span class="comment"># # 使用 asyncio.run() 来启动异步程序</span></span><br><span class="line"><span class="comment"># result = asyncio.run(run_async_tasks())</span></span><br><span class="line"><span class="comment"># print(result)</span></span><br><span class="line"><span class="comment"># 在 Jupyter 单元格中直接调用</span></span><br><span class="line">result = <span class="keyword">await</span> run_async_tasks()</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<pre><code>异步调用完成
其他任务完成
总共耗时：5.012909412384033秒
</code></pre>
<p><strong>异步调用之ainvoke()</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> inspect</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;ainvoke 是协程函数:&quot;</span>, inspect.iscoroutinefunction(chat_model.ainvoke))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;invoke 是协程函数:&quot;</span>, inspect.iscoroutinefunction(chat_model.invoke))</span><br></pre></td></tr></table></figure>

<pre><code>ainvoke 是协程函数: True
invoke 是协程函数: False
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage, SystemMessage</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line"><span class="comment"># 同步调用（对比组）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sync_test</span>():</span><br><span class="line">    messages1 = [SystemMessage(content=<span class="string">&quot;你是一位乐于助人的智能小助手&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;请帮我介绍一下什么是机器学习&quot;</span>), ]</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    response = chat_model.invoke(messages1) <span class="comment"># 同步调用</span></span><br><span class="line">    duration = time.time() - start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;同步调用耗时：<span class="subst">&#123;duration:<span class="number">.2</span>f&#125;</span>秒&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> response, duration</span><br><span class="line"><span class="comment"># 异步调用（实验组）</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">async_test</span>():</span><br><span class="line">    messages1 = [SystemMessage(content=<span class="string">&quot;你是一位乐于助人的智能小助手&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;请帮我介绍一下什么是机器学习&quot;</span>), ]</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    response = <span class="keyword">await</span> chat_model.ainvoke(messages1) <span class="comment"># 异步调用</span></span><br><span class="line">    duration = time.time() - start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;异步调用耗时：<span class="subst">&#123;duration:<span class="number">.2</span>f&#125;</span>秒&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> response, duration</span><br><span class="line"><span class="comment"># 运行测试</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 运行同步测试</span></span><br><span class="line">    sync_response, sync_duration = sync_test()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;同步响应内容: <span class="subst">&#123;sync_response.content[:<span class="number">100</span>]&#125;</span>...\n&quot;</span>)</span><br><span class="line">    <span class="comment"># 运行异步测试</span></span><br><span class="line">    async_response, async_duration = asyncio.run(async_test())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;异步响应内容: <span class="subst">&#123;async_response.content[:<span class="number">100</span>]&#125;</span>...\n&quot;</span>)</span><br><span class="line">    <span class="comment"># 并发测试 - 修复版本</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== 并发测试 ===&quot;</span>)</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">run_concurrent_tests</span>():</span><br><span class="line">        <span class="comment"># 创建3个异步任务</span></span><br><span class="line">        tasks = [async_test() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)]</span><br><span class="line">        <span class="comment"># 并发执行所有任务</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">await</span> asyncio.gather(*tasks)</span><br><span class="line">    <span class="comment"># 执行并发测试</span></span><br><span class="line">    results = asyncio.run(run_concurrent_tests())</span><br><span class="line">    total_time = time.time() - start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n3个并发异步调用总耗时: <span class="subst">&#123;total_time:<span class="number">.2</span>f&#125;</span>秒&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;平均每个调用耗时: <span class="subst">&#123;total_time / <span class="number">3</span>:<span class="number">.2</span>f&#125;</span>秒&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="4-Model-I-O之Prompt-Template"><a href="#4-Model-I-O之Prompt-Template" class="headerlink" title="4. Model I&#x2F;O之Prompt Template"></a>4. Model I&#x2F;O之Prompt Template</h2><p>Prompt Template，通过模板管理大模型的输入。<br>几种不同类型的提示模板：</p>
<ul>
<li><code>PromptTemplate</code> ：LLM提示模板，用于生成字符串提示。它使用 Python 的字符串来模板提示。</li>
<li><code>ChatPromptTemplate</code> ：聊天提示模板，用于组合各种角色的消息模板，传入聊天模型。</li>
<li><code>XxxMessagePromptTemplate</code> ：消息模板词模板，包括：SystemMessagePromptTemplate、HumanMessagePromptTemplate、AIMessagePromptTemplate、ChatMessagePromptTemplate等</li>
<li><code>FewShotPromptTemplate</code> ：样本提示词模板，通过示例来教模型如何回答</li>
<li><code>PipelinePrompt</code> ：管道提示词模板，用于把几个提示词组合在一起使用。</li>
<li>自定义模板 ：允许基于其它模板类来定制自己的提示词模板。</li>
</ul>
<p><strong>模板导入</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> FewShotPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> (</span><br><span class="line">    ChatMessagePromptTemplate,</span><br><span class="line">    SystemMessagePromptTemplate,</span><br><span class="line">    AIMessagePromptTemplate,</span><br><span class="line">    HumanMessagePromptTemplate,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="4-3-具体使用：PromptTemplate"><a href="#4-3-具体使用：PromptTemplate" class="headerlink" title="4.3 具体使用：PromptTemplate"></a>4.3 具体使用：PromptTemplate</h3><p>PromptTemplate类，用于快速构建 包含变量 的提示词模板，并通过 传入不同的参数值 生成自定义的提示词。</p>
<p>主要参数介绍：</p>
<ul>
<li>template：定义提示词模板的字符串，其中包含 文本 和 变量占位符（如{name}） ；</li>
<li>input_variables： 列表，指定了模板中使用的变量名称，在调用模板时被替换；</li>
<li>partial_variables：字典，用于定义模板中一些固定的变量名。这些值不需要再每次调用时被替换。</li>
</ul>
<p>函数介绍：</p>
<p>format()：给input_variables变量赋值，并返回提示词。利用format() 进行格式化时就一定要赋<br>值，否则会报错。当在template中未设置input_variables，则会自动忽略。</p>
<h4 id="4-3-2-两种实例化方式"><a href="#4-3-2-两种实例化方式" class="headerlink" title="4.3.2 两种实例化方式"></a>4.3.2 两种实例化方式</h4><p><strong>方式1：使用构造方法</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子1</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="comment"># 定义模板：描述主题的应用</span></span><br><span class="line">template = PromptTemplate(template=<span class="string">&quot;请简要描述&#123;topic&#125;的应用。&quot;</span>, input_variables=[<span class="string">&quot;topic&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(template)</span><br></pre></td></tr></table></figure>

<pre><code>input_variables=[&#39;topic&#39;] input_types={} partial_variables={} template=&#39;请简要描述{topic}的应用。&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用模板生成提示词</span></span><br><span class="line">prompt_1 = template.<span class="built_in">format</span>(topic=<span class="string">&quot;机器学习&quot;</span>)</span><br><span class="line">prompt_2 = template.<span class="built_in">format</span>(topic=<span class="string">&quot;自然语言处理&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;提示词1:&quot;</span>, prompt_1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;提示词2:&quot;</span>, prompt_2)</span><br></pre></td></tr></table></figure>

<pre><code>提示词1: 请简要描述机器学习的应用。
提示词2: 请简要描述自然语言处理的应用。
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子2：定义多变量模板</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="comment">#定义多变量模板</span></span><br><span class="line">template = PromptTemplate(</span><br><span class="line">    template=<span class="string">&quot;请评价&#123;product&#125;的优缺点，包括&#123;aspect1&#125;和&#123;aspect2&#125;。&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;product&quot;</span>, <span class="string">&quot;aspect1&quot;</span>, <span class="string">&quot;aspect2&quot;</span>]</span><br><span class="line">)</span><br><span class="line"><span class="comment">#使用模板生成提示词</span></span><br><span class="line">prompt_1 = template.<span class="built_in">format</span>(product=<span class="string">&quot;智能手机&quot;</span>, aspect1=<span class="string">&quot;电池续航&quot;</span>, aspect2=<span class="string">&quot;拍照质量&quot;</span>)</span><br><span class="line">prompt_2 = template.<span class="built_in">format</span>(product=<span class="string">&quot;笔记本电脑&quot;</span>, aspect1=<span class="string">&quot;处理速度&quot;</span>, aspect2=<span class="string">&quot;便携性&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;提示词1:&quot;</span>, prompt_1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;提示词2:&quot;</span>, prompt_2)</span><br></pre></td></tr></table></figure>

<pre><code>提示词1: 请评价智能手机的优缺点，包括电池续航和拍照质量。
提示词2: 请评价笔记本电脑的优缺点，包括处理速度和便携性。
</code></pre>
<p><strong>方式2：调用from_template()</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子1</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line">prompt_template = PromptTemplate.from_template(<span class="string">&quot;请给我一个关于&#123;topic&#125;的&#123;type&#125;解释。&quot;</span>)</span><br><span class="line"><span class="comment">#传入模板中的变量名</span></span><br><span class="line">prompt = prompt_template.<span class="built_in">format</span>(<span class="built_in">type</span>=<span class="string">&quot;详细&quot;</span>, topic=<span class="string">&quot;量子力学&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(prompt)</span><br></pre></td></tr></table></figure>

<pre><code>请给我一个关于量子力学的详细解释。
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子2</span></span><br><span class="line"><span class="comment">#1.导入相关的包</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="comment"># 2.定义提示词模版对象</span></span><br><span class="line">text = <span class="string">&quot;&quot;&quot;Tell me a joke&quot;&quot;&quot;</span></span><br><span class="line">prompt_template = PromptTemplate.from_template(text)</span><br><span class="line"><span class="comment"># 3.默认使用f-string进行格式化（返回格式好的字符串）</span></span><br><span class="line">prompt = prompt_template.<span class="built_in">format</span>()</span><br><span class="line"><span class="built_in">print</span>(prompt)</span><br></pre></td></tr></table></figure>

<pre><code>Tell me a joke
</code></pre>
<h4 id="4-3-3-两种新的结构形式"><a href="#4-3-3-两种新的结构形式" class="headerlink" title="4.3.3 两种新的结构形式"></a>4.3.3 两种新的结构形式</h4><p><strong>形式1：部分提示词模版</strong><br>在生成prompt前就已经提前初始化部分的提示词，实际进一步导入模版的时候只导入除已初始化的变量即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方式1：实例化过程中使用partial_variables变量</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="comment">#方式2：</span></span><br><span class="line">template2 = PromptTemplate(</span><br><span class="line">    template=<span class="string">&quot;&#123;foo&#125;&#123;bar&#125;&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;foo&quot;</span>,<span class="string">&quot;bar&quot;</span>],</span><br><span class="line">    partial_variables=&#123;<span class="string">&quot;foo&quot;</span>: <span class="string">&quot;hello&quot;</span>&#125;</span><br><span class="line">)</span><br><span class="line">prompt2 = template2.<span class="built_in">format</span>(bar=<span class="string">&quot;world&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(prompt2)</span><br></pre></td></tr></table></figure>

<pre><code>helloworld
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 PromptTemplate.partial() 方法创建部分提示模板</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line">template1 = PromptTemplate(</span><br><span class="line">    template=<span class="string">&quot;&#123;foo&#125;&#123;bar&#125;&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>]</span><br><span class="line">)</span><br><span class="line"><span class="comment">#方式1：</span></span><br><span class="line">partial_template1 = template1.partial(foo=<span class="string">&quot;hello&quot;</span>)</span><br><span class="line">prompt1 = partial_template1.<span class="built_in">format</span>(bar=<span class="string">&quot;world&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(prompt1)</span><br></pre></td></tr></table></figure>

<pre><code>helloworld
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="comment"># 完整模板</span></span><br><span class="line">full_template = <span class="string">&quot;&quot;&quot;你是一个&#123;role&#125;，请用&#123;style&#125;风格回答：</span></span><br><span class="line"><span class="string">问题：&#123;question&#125;</span></span><br><span class="line"><span class="string">答案：&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 预填充角色和风格</span></span><br><span class="line">partial_template = PromptTemplate.from_template(full_template).partial(</span><br><span class="line">    role=<span class="string">&quot;资深厨师&quot;</span>,</span><br><span class="line">    style=<span class="string">&quot;专业但幽默&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 只需提供剩余变量</span></span><br><span class="line"><span class="built_in">print</span>(partial_template.<span class="built_in">format</span>(question=<span class="string">&quot;如何煎牛排？&quot;</span>))</span><br></pre></td></tr></table></figure>

<pre><code>你是一个资深厨师，请用专业但幽默风格回答：
问题：如何煎牛排？
答案：
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">prompt_template = PromptTemplate.from_template(</span><br><span class="line">    template = <span class="string">&quot;请评价&#123;product&#125;的优缺点，包括&#123;aspect1&#125;和&#123;aspect2&#125;。&quot;</span>,</span><br><span class="line">    partial_variables= &#123;<span class="string">&quot;aspect1&quot;</span>:<span class="string">&quot;电池&quot;</span>,<span class="string">&quot;aspect2&quot;</span>:<span class="string">&quot;屏幕&quot;</span>&#125;</span><br><span class="line">)</span><br><span class="line">prompt= prompt_template.<span class="built_in">format</span>(product=<span class="string">&quot;笔记本电脑&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(prompt)</span><br></pre></td></tr></table></figure>

<pre><code>请评价笔记本电脑的优缺点，包括电池和屏幕。
</code></pre>
<p><strong>形式2：组合提示词(了解)</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line">template = (</span><br><span class="line">PromptTemplate.from_template(<span class="string">&quot;Tell me a joke about &#123;topic&#125;&quot;</span>)</span><br><span class="line">+ <span class="string">&quot;, make it funny&quot;</span></span><br><span class="line">+ <span class="string">&quot;\n\nand in &#123;language&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line">prompt = template.<span class="built_in">format</span>(topic=<span class="string">&quot;sports&quot;</span>, language=<span class="string">&quot;spanish&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(prompt)</span><br></pre></td></tr></table></figure>

<pre><code>Tell me a joke about sports, make it funny

and in spanish
</code></pre>
<h4 id="4-3-4-format-与-invoke"><a href="#4-3-4-format-与-invoke" class="headerlink" title="4.3.4 format() 与 invoke()"></a>4.3.4 format() 与 invoke()</h4><p>只要对象是RunnableSerializable接口类型，都可以使用invoke()，替换前面使用format()的调用方式。</p>
<p>format()，返回值为字符串类型；invoke()，返回值为PromptValue类型，接着调用to_string()返回字符串。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子1</span></span><br><span class="line"><span class="comment">#1.导入相关的包</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="comment"># 2.定义提示词模版对象</span></span><br><span class="line">prompt_template = PromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;Tell me a &#123;adjective&#125; joke about &#123;content&#125;.&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 3.默认使用f-string进行格式化（返回格式好的字符串）</span></span><br><span class="line">prompt_template.invoke(&#123;<span class="string">&quot;adjective&quot;</span>:<span class="string">&quot;funny&quot;</span>, <span class="string">&quot;content&quot;</span>:<span class="string">&quot;chickens&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>




<pre><code>StringPromptValue(text=&#39;Tell me a funny joke about chickens.&#39;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.导入相关的包</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="comment"># 2.使用初始化器进行实例化</span></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">input_variables=[<span class="string">&quot;adjective&quot;</span>, <span class="string">&quot;content&quot;</span>],</span><br><span class="line">template=<span class="string">&quot;Tell me a &#123;adjective&#125; joke about &#123;content&#125;&quot;</span>)</span><br><span class="line"><span class="comment"># 3. PromptTemplate底层是RunnableSerializable接口 所以可以直接使用invoke()调用</span></span><br><span class="line">prompt.invoke(&#123;<span class="string">&quot;adjective&quot;</span>: <span class="string">&quot;funny&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;chickens&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>




<pre><code>StringPromptValue(text=&#39;Tell me a funny joke about chickens&#39;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line">prompt_template = (</span><br><span class="line">PromptTemplate.from_template(<span class="string">&quot;Tell me a joke about &#123;topic&#125;&quot;</span>)</span><br><span class="line">+ <span class="string">&quot;, make it funny&quot;</span></span><br><span class="line">+ <span class="string">&quot; and in &#123;language&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line">prompt = prompt_template.invoke(&#123;<span class="string">&quot;topic&quot;</span>:<span class="string">&quot;sports&quot;</span>, <span class="string">&quot;language&quot;</span>:<span class="string">&quot;spanish&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(prompt)</span><br></pre></td></tr></table></figure>

<pre><code>text=&#39;Tell me a joke about sports, make it funny and in spanish&#39;
</code></pre>
<h4 id="4-3-5-结合LLM调用"><a href="#4-3-5-结合LLM调用" class="headerlink" title="4.3.5 结合LLM调用"></a>4.3.5 结合LLM调用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> OllamaLLM</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="comment"># llm = OllamaLLM(model=&quot;qwen:7b&quot;)</span></span><br><span class="line">llm = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line">prompt_template = PromptTemplate.from_template(</span><br><span class="line">    template=<span class="string">&quot;请评价&#123;product&#125;的优缺点，包括&#123;aspect1&#125;和&#123;aspect2&#125;。&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># prompt = prompt_template.format(product=&quot;笔记本电脑&quot;, aspect1=&quot;性能&quot;, aspect2=&quot;电池&quot;)</span></span><br><span class="line">prompt = prompt_template.invoke(&#123;<span class="string">&quot;product&quot;</span>:<span class="string">&quot;笔记本电脑&quot;</span>, <span class="string">&quot;aspect1&quot;</span>:<span class="string">&quot;性能&quot;</span>, <span class="string">&quot;aspect2&quot;</span>:<span class="string">&quot;电池&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(prompt))</span><br><span class="line"><span class="built_in">print</span>(prompt)</span><br><span class="line"></span><br><span class="line">llm.invoke(prompt)</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;langchain_core.prompt_values.StringPromptValue&#39;&gt;
text=&#39;请评价笔记本电脑的优缺点，包括性能和电池。&#39;





AIMessage(content=&#39;优点：\n\n1. 性能：笔记本电脑具有高度可定制性，可以根据用户的需求选择不同的处理器（如Intel Core i5或i7，AMD Ryzen等），内存大小，显卡类型等，从而提供强大的计算能力和图形处理能力。\n\n2. 便携性：与台式机相比，笔记本电脑体积小，重量轻，方便携带。无论是出差、旅行还是商务会议，都能轻松应对。\n\n3. 学习和工作环境：许多学校和企业都配备有笔记本电脑，为学习者或员工提供必备的工作工具。\n\n缺点：\n\n1. 续航能力：虽然笔记本电脑在便携性上有优势，但它们通常不如台式机电源稳定，因此续航能力相对较弱。对于需要长时间使用设备的用户来说，电池寿命是一个重要的考虑因素。\n\n2. 硬件升级难度：与台式机相比，笔记本电脑的硬件更换和升级往往较为复杂。如想更换显卡或增加内存容量，通常需要拆解笔记本电脑，这在一定程度上增加了维护成本。\n\n3. 价格差异较大：由于性能、品牌、配置等因素的不同，笔记本电脑的价格差异较大。对于预算有限的用户来说，在满足基本需求的前提下选择性价比高的产品更为重要。&#39;, additional_kwargs={}, response_metadata={&#39;model&#39;: &#39;qwen:7b&#39;, &#39;created_at&#39;: &#39;2026-01-06T07:29:31.5999011Z&#39;, &#39;done&#39;: True, &#39;done_reason&#39;: &#39;stop&#39;, &#39;total_duration&#39;: 62746906400, &#39;load_duration&#39;: 65089700, &#39;prompt_eval_count&#39;: 21, &#39;prompt_eval_duration&#39;: 327548900, &#39;eval_count&#39;: 261, &#39;eval_duration&#39;: 62062951800, &#39;logprobs&#39;: None, &#39;model_name&#39;: &#39;qwen:7b&#39;, &#39;model_provider&#39;: &#39;ollama&#39;}, id=&#39;lc_run--019b9235-0cb0-7242-8ab0-3d70c074ad7e-0&#39;, usage_metadata={&#39;input_tokens&#39;: 21, &#39;output_tokens&#39;: 261, &#39;total_tokens&#39;: 282})
</code></pre>
<h3 id="4-4-具体使用：ChatPromptTemplate"><a href="#4-4-具体使用：ChatPromptTemplate" class="headerlink" title="4.4 具体使用：ChatPromptTemplate"></a>4.4 具体使用：ChatPromptTemplate</h3><p>ChatPromptTemplate是创建 聊天消息列表 的提示模板。它比普通 PromptTemplate 更适合处理多角色、多轮次的对话场景。</p>
<p>特点：</p>
<p>支持 System &#x2F; Human &#x2F; AI 等不同角色的消息模板</p>
<p>对话历史维护</p>
<p>参数类型：列表参数格式是tuple类型（ role :str content :str 组合最常用）</p>
<p>元组的格式为：</p>
<p>(role: str | type, content: str | list[dict] | list[object])<br>其中 role 是：字符串（如 “system” 、 “human” 、 “ai” ）</p>
<h4 id="4-4-2-两种实例化方式"><a href="#4-4-2-两种实例化方式" class="headerlink" title="4.4.2 两种实例化方式"></a>4.4.2 两种实例化方式</h4><p><strong>方式1：使用构造方法</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="comment">#参数类型这里使用的是tuple构成的list</span></span><br><span class="line">prompt_template = ChatPromptTemplate([</span><br><span class="line">    <span class="comment"># 字符串 role + 字符串 content</span></span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个AI开发工程师. 你的名字是 &#123;name&#125;.&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;你能开发哪些AI应用?&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;ai&quot;</span>, <span class="string">&quot;我能开发很多AI应用, 比如聊天机器人, 图像识别, 自然语言处理等.&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;user_input&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#调用format()方法，返回字符串</span></span><br><span class="line">prompt = prompt_template.invoke(<span class="built_in">input</span>=&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;小谷AI&quot;</span>,<span class="string">&quot;user_input&quot;</span>:<span class="string">&quot;你能帮我做什么?&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(prompt))</span><br><span class="line"><span class="built_in">print</span>(prompt)</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;langchain_core.prompt_values.ChatPromptValue&#39;&gt;
messages=[SystemMessage(content=&#39;你是一个AI开发工程师. 你的名字是 小谷AI.&#39;, additional_kwargs={}, response_metadata={}), HumanMessage(content=&#39;你能开发哪些AI应用?&#39;, additional_kwargs={}, response_metadata={}), AIMessage(content=&#39;我能开发很多AI应用, 比如聊天机器人, 图像识别, 自然语言处理等.&#39;, additional_kwargs={}, response_metadata={}), HumanMessage(content=&#39;你能帮我做什么?&#39;, additional_kwargs={}, response_metadata={})]
</code></pre>
<p><strong>方式2：调用from_messages()</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入相关依赖</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="comment"># 定义聊天提示词模版</span></span><br><span class="line">chat_template = ChatPromptTemplate.from_messages(</span><br><span class="line">[</span><br><span class="line">(<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个有帮助的AI机器人，你的名字是&#123;name&#125;。&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;你好，最近怎么样？&quot;</span>),</span><br><span class="line">(<span class="string">&quot;ai&quot;</span>, <span class="string">&quot;我很好，谢谢！&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;user_input&#125;&quot;</span>),</span><br><span class="line">]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 格式化聊天提示词模版中的变量</span></span><br><span class="line">messages = chat_template.invoke(<span class="built_in">input</span>=&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;小明&quot;</span>, <span class="string">&quot;user_input&quot;</span>:<span class="string">&quot;你叫什么名字？&quot;</span>&#125;)</span><br><span class="line"><span class="comment"># 打印格式化后的聊天提示词模版内容</span></span><br><span class="line"><span class="built_in">print</span>(messages)</span><br></pre></td></tr></table></figure>

<pre><code>messages=[SystemMessage(content=&#39;你是一个有帮助的AI机器人，你的名字是小明。&#39;, additional_kwargs={}, response_metadata={}), HumanMessage(content=&#39;你好，最近怎么样？&#39;, additional_kwargs={}, response_metadata={}), AIMessage(content=&#39;我很好，谢谢！&#39;, additional_kwargs={}, response_metadata={}), HumanMessage(content=&#39;你叫什么名字？&#39;, additional_kwargs={}, response_metadata={})]
</code></pre>
<h4 id="4-4-3-模板调用的几种方式"><a href="#4-4-3-模板调用的几种方式" class="headerlink" title="4.4.3 模板调用的几种方式"></a>4.4.3 模板调用的几种方式</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># invoke()</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="comment">#参数类型这里使用的是tuple构成的list</span></span><br><span class="line">prompt_template = ChatPromptTemplate([</span><br><span class="line"><span class="comment"># 字符串 role + 字符串 content</span></span><br><span class="line">(<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个AI开发工程师. 你的名字是 &#123;name&#125;.&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;你能开发哪些AI应用?&quot;</span>),</span><br><span class="line">(<span class="string">&quot;ai&quot;</span>, <span class="string">&quot;我能开发很多AI应用, 比如聊天机器人, 图像识别, 自然语言处理等.&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;user_input&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line">prompt = prompt_template.invoke(&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;小谷AI&quot;</span>, <span class="string">&quot;user_input&quot;</span>:<span class="string">&quot;你能帮我做什么?&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(prompt))</span><br><span class="line"><span class="built_in">print</span>(prompt)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(prompt.messages))</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;langchain_core.prompt_values.ChatPromptValue&#39;&gt;
messages=[SystemMessage(content=&#39;你是一个AI开发工程师. 你的名字是 小谷AI.&#39;, additional_kwargs={}, response_metadata={}), HumanMessage(content=&#39;你能开发哪些AI应用?&#39;, additional_kwargs={}, response_metadata={}), AIMessage(content=&#39;我能开发很多AI应用, 比如聊天机器人, 图像识别, 自然语言处理等.&#39;, additional_kwargs={}, response_metadata={}), HumanMessage(content=&#39;你能帮我做什么?&#39;, additional_kwargs={}, response_metadata={})]
4
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># format()</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="comment">#参数类型这里使用的是tuple构成的list</span></span><br><span class="line">prompt_template = ChatPromptTemplate([</span><br><span class="line"><span class="comment"># 字符串 role + 字符串 content</span></span><br><span class="line">(<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个AI开发工程师. 你的名字是 &#123;name&#125;.&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;你能开发哪些AI应用?&quot;</span>),</span><br><span class="line">(<span class="string">&quot;ai&quot;</span>, <span class="string">&quot;我能开发很多AI应用, 比如聊天机器人, 图像识别, 自然语言处理等.&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;user_input&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#方式1：调用format()方法，返回字符串</span></span><br><span class="line">prompt = prompt_template.<span class="built_in">format</span>(name=<span class="string">&quot;小谷AI&quot;</span>, user_input=<span class="string">&quot;你能帮我做什么?&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(prompt))</span><br><span class="line"><span class="built_in">print</span>(prompt)</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;str&#39;&gt;
System: 你是一个AI开发工程师. 你的名字是 小谷AI.
Human: 你能开发哪些AI应用?
AI: 我能开发很多AI应用, 比如聊天机器人, 图像识别, 自然语言处理等.
Human: 你能帮我做什么?
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># format_messages()</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line">prompt_template = ChatPromptTemplate([</span><br><span class="line">(<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个AI开发工程师. 你的名字是 &#123;name&#125;.&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;你能开发哪些AI应用?&quot;</span>),</span><br><span class="line">(<span class="string">&quot;ai&quot;</span>, <span class="string">&quot;我能开发很多AI应用, 比如聊天机器人, 图像识别, 自然语言处理等.&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;user_input&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#调用format_messages()方法，返回消息列表</span></span><br><span class="line">prompt2 = prompt_template.format_messages(name=<span class="string">&quot;小谷AI&quot;</span>, user_input=<span class="string">&quot;你能帮我做什么?&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(prompt2))</span><br><span class="line"><span class="built_in">print</span>(prompt2)</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;list&#39;&gt;
[SystemMessage(content=&#39;你是一个AI开发工程师. 你的名字是 小谷AI.&#39;, additional_kwargs={}, response_metadata={}), HumanMessage(content=&#39;你能开发哪些AI应用?&#39;, additional_kwargs={}, response_metadata={}), AIMessage(content=&#39;我能开发很多AI应用, 比如聊天机器人, 图像识别, 自然语言处理等.&#39;, additional_kwargs={}, response_metadata={}), HumanMessage(content=&#39;你能帮我做什么?&#39;, additional_kwargs={}, response_metadata={})]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># format_prompt()</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="comment">#参数类型这里使用的是tuple构成的list</span></span><br><span class="line">prompt_template = ChatPromptTemplate([</span><br><span class="line"><span class="comment"># 字符串 role + 字符串 content</span></span><br><span class="line">(<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个AI开发工程师. 你的名字是 &#123;name&#125;.&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;你能开发哪些AI应用?&quot;</span>),</span><br><span class="line">(<span class="string">&quot;ai&quot;</span>, <span class="string">&quot;我能开发很多AI应用, 比如聊天机器人, 图像识别, 自然语言处理等.&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;user_input&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line">prompt = prompt_template.format_prompt(name=<span class="string">&quot;小谷AI&quot;</span>, user_input=<span class="string">&quot;你能帮我做什么?&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(prompt.to_messages())</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(prompt.to_messages()))</span><br></pre></td></tr></table></figure>

<pre><code>[SystemMessage(content=&#39;你是一个AI开发工程师. 你的名字是 小谷AI.&#39;, additional_kwargs={}, response_metadata={}), HumanMessage(content=&#39;你能开发哪些AI应用?&#39;, additional_kwargs={}, response_metadata={}), AIMessage(content=&#39;我能开发很多AI应用, 比如聊天机器人, 图像识别, 自然语言处理等.&#39;, additional_kwargs={}, response_metadata={}), HumanMessage(content=&#39;你能帮我做什么?&#39;, additional_kwargs={}, response_metadata={})]
&lt;class &#39;list&#39;&gt;
</code></pre>
<h4 id="4-4-4-结合LLM"><a href="#4-4-4-结合LLM" class="headerlink" title="4.4.4 结合LLM"></a>4.4.4 结合LLM</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts.chat <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="comment">######1、提供提示词#########</span></span><br><span class="line">chat_prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">(<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个数学家，你可以计算任何算式&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;我的问题：&#123;question&#125;&quot;</span>),</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 输入提示</span></span><br><span class="line">messages = chat_prompt.format_messages(question=<span class="string">&quot;我今年18岁，我的舅舅今年38岁，我的爷爷今年72岁，我和舅舅一共多少岁了？&quot;</span>)</span><br><span class="line"><span class="comment">#print(messages)</span></span><br><span class="line"><span class="comment">######2、提供大模型#########</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line"><span class="comment">######3、结合提示词，调用大模型#########</span></span><br><span class="line"><span class="comment"># 得到模型的输出</span></span><br><span class="line">output = chat_model.invoke(messages)</span><br><span class="line"><span class="comment"># 打印输出内容</span></span><br><span class="line"><span class="built_in">print</span>(output.content)</span><br></pre></td></tr></table></figure>

<pre><code>要计算你和舅舅一共多少岁，你需要将你的年龄加上你舅舅的年龄。

你的年龄 = 18岁
你舅舅的年龄 = 38岁

总年龄 = 你自己的年龄 + 你舅舅的年龄
总年龄 = 18 + 38
总年龄 = 56岁

所以，你和舅舅一共56岁。
</code></pre>
<h4 id="4-4-6-插入消息列表：MessagesPlaceholder"><a href="#4-4-6-插入消息列表：MessagesPlaceholder" class="headerlink" title="4.4.6 插入消息列表：MessagesPlaceholder"></a>4.4.6 插入消息列表：MessagesPlaceholder</h4><p>多轮对话系统存储历史消息以及Agent的中间步骤处理此功能非常有用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate, MessagesPlaceholder</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage</span><br><span class="line">prompt_template = ChatPromptTemplate.from_messages([</span><br><span class="line">(<span class="string">&quot;system&quot;</span>, <span class="string">&quot;You are a helpful assistant&quot;</span>),</span><br><span class="line">MessagesPlaceholder(<span class="string">&quot;msgs&quot;</span>)</span><br><span class="line">])</span><br><span class="line">prompt_template.invoke(&#123;<span class="string">&quot;msgs&quot;</span>: [HumanMessage(content=<span class="string">&quot;hi!&quot;</span>)]&#125;)</span><br><span class="line"><span class="comment"># prompt_template.format_messages(msgs=[HumanMessage(content=&quot;hi!&quot;)])</span></span><br></pre></td></tr></table></figure>




<pre><code>ChatPromptValue(messages=[SystemMessage(content=&#39;You are a helpful assistant&#39;, additional_kwargs={}, response_metadata={}), HumanMessage(content=&#39;hi!&#39;, additional_kwargs={}, response_metadata={})])
</code></pre>
<p>这将生成两条消息，第一条是系统消息，第二条是我们传入的 HumanMessage。 如果我们传入了 5 条消息，那么总共会生成 6 条消息（系统消息加上传入的 5 条消息）。 这对于将一系列消息插入到特定位置非常有用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 举例2：存储对话历史内容</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate, MessagesPlaceholder</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> AIMessage</span><br><span class="line">prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">[</span><br><span class="line">(<span class="string">&quot;system&quot;</span>, <span class="string">&quot;You are a helpful assistant.&quot;</span>),</span><br><span class="line">MessagesPlaceholder(<span class="string">&quot;history&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;question&#125;&quot;</span>)</span><br><span class="line">]</span><br><span class="line">)</span><br><span class="line">prompt.format_messages(</span><br><span class="line">history=[HumanMessage(content=<span class="string">&quot;1+2*3 = ?&quot;</span>),AIMessage(content=<span class="string">&quot;1+2*3=7&quot;</span>)],</span><br><span class="line">question=<span class="string">&quot;我刚才问题是什么？&quot;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>[SystemMessage(content=&#39;You are a helpful assistant.&#39;, additional_kwargs={}, response_metadata={}),
 HumanMessage(content=&#39;1+2*3 = ?&#39;, additional_kwargs={}, response_metadata={}),
 AIMessage(content=&#39;1+2*3=7&#39;, additional_kwargs={}, response_metadata={}),
 HumanMessage(content=&#39;我刚才问题是什么？&#39;, additional_kwargs={}, response_metadata={})]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.导入相关包</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> (SystemMessagePromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder)</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage</span><br><span class="line"><span class="comment"># 2.定义消息模板</span></span><br><span class="line">prompt = ChatPromptTemplate.from_messages([SystemMessagePromptTemplate.from_template(<span class="string">&quot;你是&#123;role&#125;&quot;</span>),</span><br><span class="line">MessagesPlaceholder(variable_name=<span class="string">&quot;intermediate_steps&quot;</span>),</span><br><span class="line">HumanMessagePromptTemplate.from_template(<span class="string">&quot;&#123;query&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 3.定义消息对象（运行时填充中间步骤的结果）</span></span><br><span class="line">intermediate = [</span><br><span class="line">SystemMessage(name=<span class="string">&quot;search&quot;</span>, content=<span class="string">&quot;北京: 晴, 25℃&quot;</span>)</span><br><span class="line">]</span><br><span class="line"><span class="comment"># 4.格式化聊天消息提示词模版</span></span><br><span class="line">prompt.format_messages(</span><br><span class="line">role=<span class="string">&quot;天气预报员&quot;</span>,</span><br><span class="line">intermediate_steps=intermediate,</span><br><span class="line">query=<span class="string">&quot;北京天气怎么样？&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>




<pre><code>[SystemMessage(content=&#39;你是天气预报员&#39;, additional_kwargs={}, response_metadata={}),
 SystemMessage(content=&#39;北京: 晴, 25℃&#39;, additional_kwargs={}, response_metadata={}, name=&#39;search&#39;),
 HumanMessage(content=&#39;北京天气怎么样？&#39;, additional_kwargs={}, response_metadata={})]
</code></pre>
<h3 id="4-5-具体使用：少量样本示例的提示词模板"><a href="#4-5-具体使用：少量样本示例的提示词模板" class="headerlink" title="4.5 具体使用：少量样本示例的提示词模板"></a>4.5 具体使用：少量样本示例的提示词模板</h3><p>在构建prompt时，可以通过构建一个 少量示例列表 去进一步格式化prompt，这是一种简单但强大的指<br>导生成的方式，在某些情况下可以 显著提高模型性能 。</p>
<p>少量示例提示模板可以由 一组示例 或一个负责从定义的集合中选择 一部分示例 的示例选择器构建。</p>
<p>前者：使用 FewShotPromptTemplate 或 FewShotChatMessagePromptTemplate</p>
<p>后者：使用 Example selectors(示例选择器)</p>
<p>每个示例的结构都是一个 字典 ，其中 键 是输入变量， 值 是输入变量的值。</p>
<h4 id="4-5-2-FewShotPromptTemplate的使用"><a href="#4-5-2-FewShotPromptTemplate的使用" class="headerlink" title="4.5.2 FewShotPromptTemplate的使用"></a>4.5.2 FewShotPromptTemplate的使用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts.few_shot <span class="keyword">import</span> FewShotPromptTemplate</span><br><span class="line"><span class="comment">#1、创建示例集合</span></span><br><span class="line">examples = [</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;北京天气怎么样&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;北京市&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;南京下雨吗&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;南京市&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;武汉热吗&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;武汉市&quot;</span>&#125;</span><br><span class="line">]</span><br><span class="line"><span class="comment">#2、创建PromptTemplate实例</span></span><br><span class="line">example_prompt = PromptTemplate.from_template(</span><br><span class="line">template=<span class="string">&quot;Input: &#123;input&#125;\nOutput: &#123;output&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">#3、创建FewShotPromptTemplate实例</span></span><br><span class="line">prompt = FewShotPromptTemplate(</span><br><span class="line">examples=examples,</span><br><span class="line">example_prompt=example_prompt,</span><br><span class="line">suffix=<span class="string">&quot;Input: &#123;input&#125;\nOutput:&quot;</span>, <span class="comment"># 要放在示例后面的提示模板字符串。</span></span><br><span class="line">input_variables=[<span class="string">&quot;input&quot;</span>] <span class="comment"># 传入的变量</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">#4、调用</span></span><br><span class="line">prompt = prompt.invoke(&#123;<span class="string">&quot;input&quot;</span>:<span class="string">&quot;长沙多少度&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;===Prompt===&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(prompt)</span><br></pre></td></tr></table></figure>

<pre><code>===Prompt===
text=&#39;Input: 北京天气怎么样\nOutput: 北京市\n\nInput: 南京下雨吗\nOutput: 南京市\n\nInput: 武汉热吗\nOutput: 武汉市\n\nInput: 长沙多少度\nOutput:&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="comment">#获取大模型</span></span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line"><span class="comment">#调用</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;===Response===&quot;</span>)</span><br><span class="line">response = chat_model.invoke(prompt)</span><br><span class="line"><span class="built_in">print</span>(response.content) <span class="comment"># ???? 结果并非长沙市，是因为7b？</span></span><br></pre></td></tr></table></figure>

<pre><code>===Response===
长沙当前温度数据，请提供最新的气象信息，以便我能给出准确的回答。
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1、创建提示模板</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="comment"># 创建提示模板，配置一个提示模板，将一个示例格式化为字符串</span></span><br><span class="line">prompt_template = <span class="string">&quot;你是一个数学专家,算式： &#123;input&#125; 值： &#123;output&#125; 使用： &#123;description&#125; &quot;</span></span><br><span class="line"><span class="comment"># 这是一个提示模板，用于设置每个示例的格式</span></span><br><span class="line">prompt_sample = PromptTemplate.from_template(prompt_template)</span><br><span class="line"><span class="comment">#2、提供示例</span></span><br><span class="line">examples = [</span><br><span class="line">    &#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;2+2&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;4&quot;</span>, <span class="string">&quot;description&quot;</span>: <span class="string">&quot;加法运算&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;5-2&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;3&quot;</span>, <span class="string">&quot;description&quot;</span>: <span class="string">&quot;减法运算&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line"><span class="comment">#3、创建一个FewShotPromptTemplate对象</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts.few_shot <span class="keyword">import</span> FewShotPromptTemplate</span><br><span class="line">prompt = FewShotPromptTemplate(</span><br><span class="line">examples=examples,</span><br><span class="line">example_prompt=prompt_sample,</span><br><span class="line">suffix=<span class="string">&quot;你是一个数学专家,算式: &#123;input&#125; 值: &#123;output&#125;&quot;</span>,</span><br><span class="line">input_variables=[<span class="string">&quot;input&quot;</span>, <span class="string">&quot;output&quot;</span>]</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(prompt.invoke(&#123;<span class="string">&quot;input&quot;</span>:<span class="string">&quot;2*5&quot;</span>, <span class="string">&quot;output&quot;</span>:<span class="string">&quot;10&quot;</span>&#125;))</span><br><span class="line"><span class="comment">#4、初始化大模型，然后调用</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line">result = chat_model.invoke(prompt.invoke(&#123;<span class="string">&quot;input&quot;</span>:<span class="string">&quot;2*5&quot;</span>, <span class="string">&quot;output&quot;</span>:<span class="string">&quot;10&quot;</span>&#125;))</span><br><span class="line"><span class="built_in">print</span>(result.content) <span class="comment"># 使用: 乘法运算</span></span><br></pre></td></tr></table></figure>

<pre><code>text=&#39;你是一个数学专家,算式： 2+2 值： 4 使用： 加法运算 \n\n你是一个数学专家,算式： 5-2 值： 3 使用： 减法运算 \n\n你是一个数学专家,算式: 2*5 值: 10&#39;
你是一个数学专家，以下是一些具体的解释和使用场景：

1. 算式： 2+2
   值： 4
   使用： 这是一个基础的加法运算。结果表明，将两个2相加得到4。

2. 算式： 5-2
   值： 3
   使用： 这是一个减法运算。通过从5中减去2，我们得到的结果是3。

3. 算式： 2*5
   值： 10
   使用： 这是一个乘法运算。将数字2与5相乘，得到的积是10。
</code></pre>
<h4 id="4-5-3-FewShotChatMessagePromptTemplate的使用"><a href="#4-5-3-FewShotChatMessagePromptTemplate的使用" class="headerlink" title="4.5.3 FewShotChatMessagePromptTemplate的使用"></a>4.5.3 FewShotChatMessagePromptTemplate的使用</h4><p>除了FewShotPromptTemplate之外，FewShotChatMessagePromptTemplate是专门为 聊天对话场景 设计的少样本（few-shot）提示模板，它继承自 FewShotPromptTemplate ，但针对聊天消息的格式进行了优化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> (FewShotChatMessagePromptTemplate, ChatPromptTemplate)</span><br><span class="line"><span class="comment"># 1.示例消息格式</span></span><br><span class="line">examples = [</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;1+1等于几？&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;1+1等于2&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;法国的首都是？&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;巴黎&quot;</span>&#125;</span><br><span class="line">]</span><br><span class="line"><span class="comment"># 2.定义示例的消息格式提示词模版</span></span><br><span class="line">msg_example_prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">(<span class="string">&quot;ai&quot;</span>, <span class="string">&quot;&#123;output&#125;&quot;</span>),</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 3.定义FewShotChatMessagePromptTemplate对象</span></span><br><span class="line">few_shot_prompt = FewShotChatMessagePromptTemplate(</span><br><span class="line">example_prompt=msg_example_prompt,</span><br><span class="line">examples=examples</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 4.输出格式化后的消息</span></span><br><span class="line"><span class="built_in">print</span>(few_shot_prompt.<span class="built_in">format</span>())</span><br></pre></td></tr></table></figure>

<pre><code>Human: 1+1等于几？
AI: 1+1等于2
Human: 法国的首都是？
AI: 巴黎
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关包</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> (FewShotChatMessagePromptTemplate,</span><br><span class="line">ChatPromptTemplate)</span><br><span class="line"><span class="comment"># 2.定义示例组</span></span><br><span class="line">examples = [</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;2🦜2&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;4&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;2🦜3&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;8&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line"><span class="comment"># 3.定义示例的消息格式提示词模版</span></span><br><span class="line">example_prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">(<span class="string">&#x27;human&#x27;</span>, <span class="string">&#x27;&#123;input&#125; 是多少?&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;ai&#x27;</span>, <span class="string">&#x27;&#123;output&#125;&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 4.定义FewShotChatMessagePromptTemplate对象</span></span><br><span class="line">few_shot_prompt = FewShotChatMessagePromptTemplate(</span><br><span class="line">examples=examples, <span class="comment"># 示例组</span></span><br><span class="line">example_prompt=example_prompt, <span class="comment"># 示例提示词词模版</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 5.输出完整提示词的消息模版</span></span><br><span class="line">final_prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">[</span><br><span class="line">(<span class="string">&#x27;system&#x27;</span>, <span class="string">&#x27;你是一个数学奇才&#x27;</span>),</span><br><span class="line">few_shot_prompt,</span><br><span class="line">(<span class="string">&#x27;human&#x27;</span>, <span class="string">&#x27;&#123;input&#125;&#x27;</span>),</span><br><span class="line">]</span><br><span class="line">)</span><br><span class="line"><span class="comment">#6.提供大模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>, temperature=<span class="number">0.4</span>)</span><br><span class="line">chat_model.invoke(final_prompt.invoke(<span class="built_in">input</span>=<span class="string">&quot;2🦜4&quot;</span>)).content</span><br></pre></td></tr></table></figure>




<pre><code>&#39;16&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关包</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> (FewShotChatMessagePromptTemplate,</span><br><span class="line">ChatPromptTemplate)</span><br><span class="line"><span class="comment"># 2.定义示例组</span></span><br><span class="line">examples = [</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;2+2&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;4&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;2+3&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;5&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line"><span class="comment"># 3.定义示例的消息格式提示词模版</span></span><br><span class="line">example_prompt = ChatPromptTemplate.from_messages([(<span class="string">&#x27;human&#x27;</span>, <span class="string">&#x27;What is &#123;input&#125;?&#x27;</span>), (<span class="string">&#x27;ai&#x27;</span>, <span class="string">&#x27;&#123;output&#125;&#x27;</span>)])</span><br><span class="line"><span class="comment"># 4.定义FewShotChatMessagePromptTemplate对象</span></span><br><span class="line">few_shot_prompt = FewShotChatMessagePromptTemplate(</span><br><span class="line">examples=examples, <span class="comment"># 示例组</span></span><br><span class="line">example_prompt=example_prompt, <span class="comment"># 示例提示词词模版</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 5.输出完整提示词的消息模版</span></span><br><span class="line">final_prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">[</span><br><span class="line">(<span class="string">&#x27;system&#x27;</span>, <span class="string">&#x27;You are a helpful AI Assistant&#x27;</span>),</span><br><span class="line">few_shot_prompt,</span><br><span class="line">(<span class="string">&#x27;human&#x27;</span>, <span class="string">&#x27;&#123;input&#125;&#x27;</span>),</span><br><span class="line">]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 6.格式化完整消息</span></span><br><span class="line"><span class="comment">#final_prompt.format(input=&quot;What is 4+4?&quot;)</span></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">final_prompt.format_messages(<span class="built_in">input</span>=<span class="string">&quot;What is 4+4?&quot;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>[SystemMessage(content=&#39;You are a helpful AI Assistant&#39;, additional_kwargs={}, response_metadata={}),
 HumanMessage(content=&#39;What is 2+2?&#39;, additional_kwargs={}, response_metadata={}),
 AIMessage(content=&#39;4&#39;, additional_kwargs={}, response_metadata={}),
 HumanMessage(content=&#39;What is 2+3?&#39;, additional_kwargs={}, response_metadata={}),
 AIMessage(content=&#39;5&#39;, additional_kwargs={}, response_metadata={}),
 HumanMessage(content=&#39;What is 4+4?&#39;, additional_kwargs={}, response_metadata={})]
</code></pre>
<h4 id="4-5-4-Example-selectors-示例选择器"><a href="#4-5-4-Example-selectors-示例选择器" class="headerlink" title="4.5.4 Example selectors(示例选择器)"></a>4.5.4 Example selectors(示例选择器)</h4><p>前面FewShotPromptTemplate的特点是，无论输入什么问题，都会包含全部示例。在实际开发中，我<br>们可以根据当前输入，使用示例选择器，从大量候选示例中选取最相关的示例子集。<br>使用的好处：避免盲目传递所有示例，减少 token 消耗的同时，还可以提升输出效果。</p>
<p>示例选择策略：语义相似选择、长度选择、最大边际相关示例选择等</p>
<p>语义相似选择 ：通过余弦相似度等度量方式评估语义相关性，选择与输入问题最相似的 k 个示<br>例。</p>
<p>长度选择 ：根据输入文本的长度，从候选示例中筛选出长度最匹配的示例。增强模型对文本结构的<br>理解。比语义相似度计算更轻量，适合对响应速度要求高的场景。</p>
<p>最大边际相关示例选择 ：优先选择与输入问题语义相似的示例；同时，通过惩罚机制避免返回同质<br>化的内容</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关包</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain_core.example_selectors <span class="keyword">import</span> SemanticSimilarityExampleSelector</span><br><span class="line"><span class="keyword">from</span> langchain_huggingface <span class="keyword">import</span> HuggingFaceEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> OllamaEmbeddings</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.定义嵌入模型</span></span><br><span class="line">embeddings_model = OllamaEmbeddings(</span><br><span class="line">    model=<span class="string">&quot;nomic-embed-text&quot;</span>,</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># embeddings_model = HuggingFaceEmbeddings(model_name=&quot;all-MiniLM-L6-v2&quot;)</span></span><br><span class="line"><span class="comment"># 3.定义示例组</span></span><br><span class="line">examples = [</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">&quot;question&quot;</span>: <span class="string">&quot;谁活得更久，穆罕默德·阿里还是艾伦·图灵?&quot;</span>,</span><br><span class="line"><span class="string">&quot;answer&quot;</span>: <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">接下来还需要问什么问题吗？</span></span><br><span class="line"><span class="string">追问：穆罕默德·阿里去世时多大年纪？</span></span><br><span class="line"><span class="string">中间答案：穆罕默德·阿里去世时享年74岁。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>,</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">&quot;question&quot;</span>: <span class="string">&quot;craigslist的创始人是什么时候出生的？&quot;</span>,</span><br><span class="line"><span class="string">&quot;answer&quot;</span>: <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">接下来还需要问什么问题吗？</span></span><br><span class="line"><span class="string">追问：谁是craigslist的创始人？</span></span><br><span class="line"><span class="string">中级答案：Craigslist是由克雷格·纽马克创立的。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>,</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">&quot;question&quot;</span>: <span class="string">&quot;谁是乔治·华盛顿的外祖父？&quot;</span>,</span><br><span class="line"><span class="string">&quot;answer&quot;</span>: <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">接下来还需要问什么问题吗？</span></span><br><span class="line"><span class="string">追问：谁是乔治·华盛顿的母亲？</span></span><br><span class="line"><span class="string">中间答案：乔治·华盛顿的母亲是玛丽·鲍尔·华盛顿。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>,</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">&quot;question&quot;</span>: <span class="string">&quot;《大白鲨》和《皇家赌场》的导演都来自同一个国家吗？&quot;</span>,</span><br><span class="line"><span class="string">&quot;answer&quot;</span>: <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">接下来还需要问什么问题吗？</span></span><br><span class="line"><span class="string">追问：《大白鲨》的导演是谁？</span></span><br><span class="line"><span class="string">中级答案：《大白鲨》的导演是史蒂文·斯皮尔伯格。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>,</span><br><span class="line">&#125;,</span><br><span class="line">]</span><br><span class="line"><span class="comment"># 4.定义示例选择器</span></span><br><span class="line">example_selector = SemanticSimilarityExampleSelector.from_examples(</span><br><span class="line"><span class="comment"># 这是可供选择的示例列表</span></span><br><span class="line">examples,</span><br><span class="line"><span class="comment"># 这是用于生成嵌入的嵌入类，用于衡量语义相似性</span></span><br><span class="line">embeddings_model,</span><br><span class="line"><span class="comment"># 这是用于存储嵌入并进行相似性搜索的 VectorStore 类</span></span><br><span class="line">Chroma,</span><br><span class="line"><span class="comment"># 这是要生成的示例数量</span></span><br><span class="line">k=<span class="number">1</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 选择与输入最相似的示例</span></span><br><span class="line">question = <span class="string">&quot;玛丽·鲍尔·华盛顿的父亲是谁?&quot;</span></span><br><span class="line">selected_examples = example_selector.select_examples(&#123;<span class="string">&quot;question&quot;</span>: question&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;与输入最相似的示例：<span class="subst">&#123;selected_examples&#125;</span>&quot;</span>) <span class="comment"># nomic-embed-text效果并不好</span></span><br><span class="line"><span class="comment"># for example in selected_examples:</span></span><br><span class="line"><span class="comment"># print(&quot;\n&quot;)</span></span><br><span class="line"><span class="comment"># for k, v in example.items():</span></span><br><span class="line"><span class="comment"># print(f&quot;&#123;k&#125;: &#123;v&#125;&quot;)</span></span><br></pre></td></tr></table></figure>

<pre><code>与输入最相似的示例：[{&#39;answer&#39;: &#39;\n接下来还需要问什么问题吗？\n追问：穆罕默德·阿里去世时多大年纪？\n中间答案：穆罕默德·阿里去世时享年74岁。\n&#39;, &#39;question&#39;: &#39;谁活得更久，穆罕默德·阿里还是艾伦·图灵?&#39;}]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关包</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_core.example_selectors <span class="keyword">import</span> SemanticSimilarityExampleSelector</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> FewShotPromptTemplate, PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> OllamaEmbeddings</span><br><span class="line"><span class="comment"># 2.定义示例提示词模版</span></span><br><span class="line">example_prompt = PromptTemplate.from_template(</span><br><span class="line">template=<span class="string">&quot;Input: &#123;input&#125;\nOutput: &#123;output&#125;&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 3.创建一个示例提示词模版</span></span><br><span class="line">examples = [</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;高兴&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;悲伤&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;高&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;矮&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;长&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;短&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;精力充沛&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;无精打采&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;阳光&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;阴暗&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;粗糙&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;光滑&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;干燥&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;潮湿&quot;</span>&#125;,</span><br><span class="line">&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;富裕&quot;</span>, <span class="string">&quot;output&quot;</span>: <span class="string">&quot;贫穷&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line"><span class="comment"># 4.定义嵌入模型</span></span><br><span class="line">embeddings = OllamaEmbeddings(</span><br><span class="line">model=<span class="string">&quot;mxbai-embed-large&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 5.创建语义相似性示例选择器</span></span><br><span class="line">example_selector = SemanticSimilarityExampleSelector.from_examples(</span><br><span class="line">examples,</span><br><span class="line">embeddings,</span><br><span class="line">FAISS,</span><br><span class="line">k=<span class="number">2</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line"><span class="comment">#example_selector = SemanticSimilarityExampleSelector(</span></span><br><span class="line"><span class="comment"># examples,</span></span><br><span class="line"><span class="comment"># embeddings,</span></span><br><span class="line"><span class="comment"># FAISS,</span></span><br><span class="line"><span class="comment"># k=2</span></span><br><span class="line"><span class="comment">#)</span></span><br><span class="line"><span class="comment"># 6.定义小样本提示词模版</span></span><br><span class="line">similar_prompt = FewShotPromptTemplate(</span><br><span class="line">example_selector=example_selector,</span><br><span class="line">example_prompt=example_prompt,</span><br><span class="line">prefix=<span class="string">&quot;给出每个词组的反义词&quot;</span>,</span><br><span class="line">suffix=<span class="string">&quot;Input: &#123;word&#125;\nOutput:&quot;</span>,</span><br><span class="line">input_variables=[<span class="string">&quot;word&quot;</span>],</span><br><span class="line">)</span><br><span class="line">response = similar_prompt.invoke(&#123;<span class="string">&quot;word&quot;</span>:<span class="string">&quot;忧郁&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br></pre></td></tr></table></figure>

<pre><code>给出每个词组的反义词

Input: 长
Output: 短

Input: 干燥
Output: 潮湿

Input: 忧郁
Output:
</code></pre>
<h2 id="5、Model-I-O之Output-Parsers"><a href="#5、Model-I-O之Output-Parsers" class="headerlink" title="5、Model I&#x2F;O之Output Parsers"></a>5、Model I&#x2F;O之Output Parsers</h2><p>语言模型返回的内容通常都是字符串的格式（文本格式），但在实际AI应用开发过程中，往往希望model可以返回更直观、更格式化的内容，以确保应用能够顺利进行后续的逻辑处理。此时，LangChain提供的 输出解析器 就派上用场了。</p>
<p>输出解析器（Output Parser）负责获取 LLM 的输出并将其转换为更合适的格式。这在应用开发中及其重要。</p>
<h3 id="5-1-输出解析器的分类"><a href="#5-1-输出解析器的分类" class="headerlink" title="5.1 输出解析器的分类"></a>5.1 输出解析器的分类</h3><p>LangChain有许多不同类型的输出解析器</p>
<ul>
<li>StrOutputParser ：字符串解析器</li>
<li>JsonOutputParser ：JSON解析器，确保输出符合特定JSON对象格式</li>
<li>XMLOutputParser ：XML解析器，允许以流行的XML格式从LLM获取结果</li>
<li>CommaSeparatedListOutputParser ：CSV解析器，模型的输出以逗号分隔，以列表形式返回输出</li>
<li>DatetimeOutputParser ：日期时间解析器，可用于将 LLM 输出解析为日期时间格式</li>
</ul>
<p>除了上述常用的输出解析器之外，还有：</p>
<ul>
<li>EnumOutputParser ：枚举解析器，将LLM的输出，解析为预定义的枚举值</li>
<li>StructuredOutputParser ：将非结构化文本转换为预定义格式的结构化数据（如字典）</li>
<li>OutputFixingParser ：输出修复解析器，用于自动修复格式错误的解析器，比如将返回的不符合<br>预期格式的输出，尝试修正为正确的结构化数据（如 JSON）</li>
<li>RetryOutputParser ：重试解析器，当主解析器（如 JSONOutputParser）因格式错误无法解析<br>LLM 的输出时，通过调用另一个 LLM 自动修正错误，并重新尝试解析</li>
</ul>
<h3 id="5-2-具体解析器的使用"><a href="#5-2-具体解析器的使用" class="headerlink" title="5.2 具体解析器的使用"></a>5.2 具体解析器的使用</h3><h4 id="5-2-1字符串解析器-StrOutputParser"><a href="#5-2-1字符串解析器-StrOutputParser" class="headerlink" title="5.2.1字符串解析器 StrOutputParser"></a>5.2.1字符串解析器 StrOutputParser</h4><p>StrOutputParser 简单地将 任何输入 转换为 字符串 。它是一个简单的解析器，从结果中提取content字段</p>
<p>举例：将一个对话模型的输出结果，解析为字符串输出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage, SystemMessage</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line">messages = [</span><br><span class="line">SystemMessage(content=<span class="string">&quot;将以下内容从英语翻译成中文&quot;</span>),</span><br><span class="line">HumanMessage(content=<span class="string">&quot;It&#x27;s a nice day today&quot;</span>),</span><br><span class="line">]</span><br><span class="line">result = chat_model.invoke(messages)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(result))</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line">parser = StrOutputParser()</span><br><span class="line"><span class="comment">#使用parser处理model返回的结果</span></span><br><span class="line">response = parser.invoke(result)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;langchain_core.messages.ai.AIMessage&#39;&gt;
content=&#39;今天是个美好的日子。&#39; additional_kwargs={} response_metadata={&#39;model&#39;: &#39;qwen:7b&#39;, &#39;created_at&#39;: &#39;2026-01-07T05:39:40.8936112Z&#39;, &#39;done&#39;: True, &#39;done_reason&#39;: &#39;stop&#39;, &#39;total_duration&#39;: 9158606800, &#39;load_duration&#39;: 5223276500, &#39;prompt_eval_count&#39;: 27, &#39;prompt_eval_duration&#39;: 2815282500, &#39;eval_count&#39;: 6, &#39;eval_duration&#39;: 1106177800, &#39;logprobs&#39;: None, &#39;model_name&#39;: &#39;qwen:7b&#39;, &#39;model_provider&#39;: &#39;ollama&#39;} id=&#39;lc_run--019b96f7-a914-7072-b0f0-b3be51b220c1-0&#39; usage_metadata={&#39;input_tokens&#39;: 27, &#39;output_tokens&#39;: 6, &#39;total_tokens&#39;: 33}
&lt;class &#39;str&#39;&gt;
今天是个美好的日子。
</code></pre>
<h4 id="5-2-2-JSON解析器-JsonOutputParser"><a href="#5-2-2-JSON解析器-JsonOutputParser" class="headerlink" title="5.2.2 JSON解析器 JsonOutputParser"></a>5.2.2 JSON解析器 JsonOutputParser</h4><p>JsonOutputParser，即JSON输出解析器，是一种用于将大模型的 自由文本输出 转换为 结构化JSON数据 的工具。</p>
<p>适合场景：特别适用于需要严格结构化输出的场景，比如 API 调用、数据存储或下游任务处理。</p>
<p>实现方式</p>
<p>方式1：用户自己通过提示词指明返回Json格式</p>
<p>方式2：借助JsonOutputParser的 get_format_instructions() ，生成格式说明，指导模型输出<br>JSON 结构</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> JsonOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line">chat_prompt_template = ChatPromptTemplate.from_messages([</span><br><span class="line">(<span class="string">&quot;system&quot;</span>,<span class="string">&quot;你是一个靠谱的&#123;role&#125;&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>,<span class="string">&quot;&#123;question&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line">parser = JsonOutputParser()</span><br><span class="line"><span class="comment"># 方式1：</span></span><br><span class="line"><span class="comment"># result = chat_model.invoke(chat_prompt_template.format_messages(role=&quot;人工智能专家&quot;,question=&quot;人工智能用英文怎么说？问题用q表示，答案用a表示，返回一个JSON格式&quot;))</span></span><br><span class="line"><span class="comment"># print(result)</span></span><br><span class="line"><span class="comment"># print(type(result))</span></span><br><span class="line"><span class="comment"># parser.invoke(result)</span></span><br><span class="line"><span class="comment"># 方式2：</span></span><br><span class="line">chain = chat_prompt_template | chat_model | parser</span><br><span class="line">chain.invoke(&#123;<span class="string">&quot;role&quot;</span>:<span class="string">&quot;人工智能专家&quot;</span>,<span class="string">&quot;question&quot;</span> : <span class="string">&quot;人工智能用英文怎么说？问题用q表示，答案用a表示，返回一个JSON格式&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>




<pre><code>{&#39;question&#39;: &#39;人工智能&#39;, &#39;answer&#39;: &#39;Artificial Intelligence&#39;}
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> JsonOutputParser</span><br><span class="line">output_parser = JsonOutputParser()</span><br><span class="line"><span class="comment"># 返回一些指令或模板，这些指令告诉系统如何解析或格式化输出数据</span></span><br><span class="line">format_instructions = output_parser.get_format_instructions()</span><br><span class="line"><span class="built_in">print</span>(format_instructions)</span><br></pre></td></tr></table></figure>

<pre><code>Return a JSON object.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> JsonOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 创建聊天模型</span></span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 创建要求 JSON 输出的提示词模板</span></span><br><span class="line">prompt = PromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;请以JSON格式回答：&#123;query&#125;\n&#123;format_instructions&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 创建 JSON 解析器</span></span><br><span class="line">parser = JsonOutputParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 获取格式说明</span></span><br><span class="line">format_instructions = parser.get_format_instructions()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 创建链</span></span><br><span class="line">chain = prompt | chat_model | parser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 执行链（需要确保模型按 JSON 格式输出）</span></span><br><span class="line">output = chain.invoke(&#123;</span><br><span class="line">    <span class="string">&quot;query&quot;</span>: <span class="string">&quot;给我讲一个笑话&quot;</span>,</span><br><span class="line">    <span class="string">&quot;format_instructions&quot;</span>: format_instructions</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<pre><code>{&#39;joke&#39;: &#39;为什么袜子总是只丢一只？因为丢两只根本就不会发现呀！&#39;}
</code></pre>
<h4 id="5-2-3-XML解析器-XMLOutputParser"><a href="#5-2-3-XML解析器-XMLOutputParser" class="headerlink" title="5.2.3 XML解析器 XMLOutputParser"></a>5.2.3 XML解析器 XMLOutputParser</h4><p>XMLOutputParser，将模型的自由文本输出转换为可编程处理的 XML 数据。<br>如何实现：在 PromptTemplate 中指定 XML 格式要求，让模型返回 <tag>content</tag> 形式的数<br>据。</p>
<p>注意：XMLOutputParser 不会直接将模型的输出保持为原始XML字符串，而是会解析XML并转换成</p>
<p>Python字典 （或类似结构化的数据）。目的是为了方便程序后续处理数据，而不是单纯保留XML格<br>式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化语言模型</span></span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line"><span class="comment"># 测试模型的xml解析效果</span></span><br><span class="line">actor_query = <span class="string">&quot;生成汤姆·汉克斯的简短电影记录&quot;</span></span><br><span class="line">output = chat_model.invoke(<span class="string">f&quot;&quot;&quot;<span class="subst">&#123;actor_query&#125;</span>请将影片附在&lt;movie&gt;&lt;/movie&gt;标签中&quot;&quot;&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(output)) <span class="comment"># &lt;class &#x27;langchain_core.messages.ai.AIMessage&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(output.content)  <span class="comment"># 7b很不聪明</span></span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;langchain_core.messages.ai.AIMessage&#39;&gt;
&lt;movie&gt;

标题：《阿甘正传》片段——汤姆·汉克斯饰演阿甘

导演：罗伯特·泽米吉斯

时间长度：约5分钟

剧情概述：
这段影片选取了电影《阿甘正传》的经典场景。汤姆·汉克斯饰演的阿甘，因为腿部残疾，他的生活充满了曲折。但无论何时，阿甘始终保持纯真的笑容和积极向上的态度。

影片附带：
视频链接：(请插入实际链接或提供在线观看服务)

影像截图：(提供几张精炼的截图)

注释：详细描述每个片段的内容

&lt;/movie&gt;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> XMLOutputParser</span><br><span class="line">output_parser = XMLOutputParser()</span><br><span class="line"><span class="comment"># 返回一些指令或模板，这些指令告诉系统如何解析或格式化输出数据</span></span><br><span class="line">format_instructions = output_parser.get_format_instructions()</span><br><span class="line"><span class="built_in">print</span>(format_instructions)</span><br></pre></td></tr></table></figure>

<pre><code>The output should be formatted as a XML file.
1. Output should conform to the tags below.
2. If tags are not given, make them on your own.
3. Remember to always open and close all the tags.

As an example, for the tags [&quot;foo&quot;, &quot;bar&quot;, &quot;baz&quot;]:
1. String &quot;&lt;foo&gt;
   &lt;bar&gt;
      &lt;baz&gt;&lt;/baz&gt;
   &lt;/bar&gt;
&lt;/foo&gt;&quot; is a well-formatted instance of the schema.
2. String &quot;&lt;foo&gt;
   &lt;bar&gt;
   &lt;/foo&gt;&quot; is a badly-formatted instance.
3. String &quot;&lt;foo&gt;
   &lt;tag&gt;
   &lt;/tag&gt;
&lt;/foo&gt;&quot; is a badly-formatted instance.

Here are the output tags:
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">None</span><br></pre></td></tr></table></figure>
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关包</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> XMLOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="comment"># 2. 初始化语言模型</span></span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line"><span class="comment"># 3.测试模型的xml解析效果</span></span><br><span class="line">actor_query = <span class="string">&quot;生成汤姆·汉克斯的简短电影记录,使用中文回复&quot;</span></span><br><span class="line"><span class="comment"># 4.定义XMLOutputParser对象</span></span><br><span class="line">parser = XMLOutputParser()</span><br><span class="line"><span class="comment"># 5.定义提示词模版对象</span></span><br><span class="line"><span class="comment"># prompt = PromptTemplate(</span></span><br><span class="line"><span class="comment"># template=&quot;&#123;query&#125;\n&#123;format_instructions&#125;&quot;,</span></span><br><span class="line"><span class="comment"># input_variables=[&quot;query&quot;,&quot;format_instructions&quot;],</span></span><br><span class="line"><span class="comment"># partial_variables=&#123;&quot;format_instructions&quot;: parser.get_format_instructions()&#125;,</span></span><br><span class="line"><span class="comment">#)</span></span><br><span class="line">prompt_template = PromptTemplate.from_template(<span class="string">&quot;&#123;query&#125;\n&#123;format_instructions&#125;&quot;</span>)</span><br><span class="line">prompt_template1 = prompt_template.partial(format_instructions=parser.get_format_instructions())</span><br><span class="line">response = chat_model.invoke(prompt_template1.<span class="built_in">format</span>(query=actor_query))</span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br></pre></td></tr></table></figure>

<pre><code><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">tom_hanks_movies</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">movie</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Tom Hanks&#x27; Early Film<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">year</span>&gt;</span>1988<span class="tag">&lt;/<span class="name">year</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">p</span>&gt;</span>This movie marked Tom Hanks&#x27; debut in Hollywood. In the film, he played a young and ambitious journalist who uncovers a dark secret.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">p</span>&gt;</span>The movie received positive reviews for Hanks&#x27; performance, which showcased his versatility as an actor.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">movie</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Additional movies can be added here --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">tom_hanks_movies</span>&gt;</span></span><br></pre></td></tr></table></figure>
In this example, I have provided two movies starring Tom Hanks in his early career. The XML output includes the necessary tags for movie titles, years, and descriptions.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方式1</span></span><br><span class="line">response = chat_model.invoke(prompt_template1.<span class="built_in">format</span>(query=actor_query))</span><br><span class="line">result = parser.invoke(response)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(result))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式2</span></span><br><span class="line"><span class="comment"># chain = prompt_template1 | chat_model | parser</span></span><br><span class="line"><span class="comment"># result = chain.invoke(&#123;&quot;query&quot;:actor_query&#125;)</span></span><br><span class="line"><span class="comment"># print(result)</span></span><br><span class="line"><span class="comment"># print(type(result))</span></span><br></pre></td></tr></table></figure>

<pre><code>{&#39;tom_hanks_movies&#39;: [{&#39;movie&#39;: [{&#39;title&#39;: &quot;Tom Hanks&#39; Early Role - Big&quot;}, {&#39;year&#39;: &#39;1988&#39;}, {&#39;description&#39;: &quot;\n            In this early role, Tom Hanks portrays a young boy named Jimmy who lives in an orphanage. The movie follows Jimmy&#39;s journey as he discovers his talent for playing the trumpet and参加一个音乐比赛.\n\n            Hanks&#39; performance in Big is often cited as a turning point in his career. The movie was commercially successful and received positive reviews, solidifying Tom Hanks&#39; status as a talented actor.\n        &quot;}]}]}
&lt;class &#39;dict&#39;&gt;
</code></pre>
<h4 id="5-2-4-列表解析器-CommaSeparatedListOutputParser"><a href="#5-2-4-列表解析器-CommaSeparatedListOutputParser" class="headerlink" title="5.2.4 列表解析器 CommaSeparatedListOutputParser"></a>5.2.4 列表解析器 CommaSeparatedListOutputParser</h4><p>列表解析器：利用此解析器可以将模型的文本响应转换为一个用 逗号分隔的列表（List[str]） 。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> CommaSeparatedListOutputParser</span><br><span class="line">output_parser = CommaSeparatedListOutputParser()</span><br><span class="line"><span class="comment"># 返回一些指令或模板，这些指令告诉系统如何解析或格式化输出数据</span></span><br><span class="line">format_instructions = output_parser.get_format_instructions()</span><br><span class="line"><span class="built_in">print</span>(format_instructions)</span><br><span class="line">messages = <span class="string">&quot;大象,猩猩,狮子&quot;</span></span><br><span class="line">result = output_parser.parse(messages)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(result))</span><br></pre></td></tr></table></figure>

<pre><code>Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`
[&#39;大象&#39;, &#39;猩猩&#39;, &#39;狮子&#39;]
&lt;class &#39;list&#39;&gt;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> CommaSeparatedListOutputParser</span><br><span class="line"><span class="comment"># 初始化语言模型</span></span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line"><span class="comment"># 创建解析器</span></span><br><span class="line">output_parser = CommaSeparatedListOutputParser()</span><br><span class="line"><span class="comment"># 创建LangChain提示模板</span></span><br><span class="line">chat_prompt = PromptTemplate.from_template(</span><br><span class="line"><span class="string">&quot;生成5个关于&#123;text&#125;的列表.\n\n&#123;format_instructions&#125;&quot;</span>,</span><br><span class="line">partial_variables=&#123;</span><br><span class="line"><span class="string">&quot;format_instructions&quot;</span>: output_parser.get_format_instructions()</span><br><span class="line">&#125;)</span><br><span class="line"><span class="comment"># 提示模板与输出解析器传递输出</span></span><br><span class="line"><span class="comment"># chat_prompt =</span></span><br><span class="line">chat_prompt.partial(format_instructions=output_parser.get_format_instructions())</span><br><span class="line"><span class="comment"># 将提示和模型合并以进行调用</span></span><br><span class="line">chain = chat_prompt | chat_model | output_parser</span><br><span class="line">res = chain.invoke(&#123;<span class="string">&quot;text&quot;</span>: <span class="string">&quot;电影&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(res))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;1. &quot;Inception&quot;&#39;, &#39;The Dark Knight&#39;, &#39;Interstellar&#39;, &#39;2. &quot;Top 10 Best Hollywood Movies&quot;&#39;, &#39;Greatest Cinematic Masterpieces&#39;, &#39;Must-Watch Film Collections&#39;, &#39;3. &quot;Sci-Fi Blockbusters&quot;&#39;, &#39;Action-Adventure Masterpieces&#39;, &#39;Futuristic Films That Transcend Time&#39;, &#39;4. &quot;List of Oscar-winning Movies&quot;&#39;, &#39;Academy Award Nominees in Cinema History&#39;, &#39;Oscar-Contender Movies for Collectors&#39;, &#39;5. &quot;Best Foreign Language Films&quot;&#39;, &#39;International Cinema masterpieces translated into English&#39;, &#39;English Subtitle Movies that Span the Globe&#39;]
&lt;class &#39;list&#39;&gt;
</code></pre>
<h4 id="日期解析器-DatetimeOutputParser-了解"><a href="#日期解析器-DatetimeOutputParser-了解" class="headerlink" title="日期解析器 DatetimeOutputParser (了解)"></a>日期解析器 DatetimeOutputParser (了解)</h4><p>利用此解析器可以直接将LLM输出解析为日期时间格式。<br>get_format_instructions()： 获取日期解析的格式化指令，指令为：<br>“Write a datetime string<br>that matches the following pattern: ‘%Y-%m-%dT%H:%M:%S.%fZ’。<br>举例：1206-08-16T17:39:06.176399Z</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts.chat <span class="keyword">import</span> HumanMessagePromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> DatetimeOutputParser</span><br><span class="line">chat_model = ChatOllama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line">chat_prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">(<span class="string">&quot;system&quot;</span>,<span class="string">&quot;&#123;format_instructions&#125;&quot;</span>),</span><br><span class="line">(<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;request&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line">output_parser = DatetimeOutputParser()</span><br><span class="line">chain = chat_prompt | chat_model | output_parser</span><br><span class="line">resp = chain.invoke(&#123;<span class="string">&quot;request&quot;</span>:<span class="string">&quot;中华人民共和国是什么时候成立的&quot;</span>,</span><br><span class="line"><span class="string">&quot;format_instructions&quot;</span>:output_parser.get_format_instructions()&#125;)</span><br><span class="line"><span class="built_in">print</span>(resp)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(resp))</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Muzi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2026/01/10/langchain-model-io/">http://example.com/2026/01/10/langchain-model-io/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">MuziCoding</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Laingchain/">Laingchain</a><a class="post-meta__tags" href="/tags/LLM/">LLM</a></div><div class="post-share"><div class="social-share" data-image="https://github.com/muzicoding/muzicoding-img/blob/master/avatar/avatar.png?raw=true" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2026/01/09/langchain-helloworld/" title="LangChain-HelloWorld"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">LangChain-HelloWorld</div></div><div class="info-2"><div class="info-item-1">1. 获取大模型12345678910111213141516171819#导入 dotenv 库的 load_dotenv 函数，用于加载环境变量文件（.env）中的配置import dotenvfrom langchain_openai import ChatOpenAIimport os# 加载环境变量文件dotenv.load_dotenv()# 获取open-ai的api密钥os.environ[&#x27;OPENAI_API_KEY&#x27;] = os.getenv(&#x27;OPENAI_API_KEY&#x27;)# 创建 ChatOpenAI 对象llm = ChatOpenAI(model=&quot;gpt-4o-mini&quot;)# 直接提供问题，并调用llmresponse = llm.invoke(&quot;什么是大模型？&quot;)# 打印结果print(response)  content=&#39;“大模型”通常指的是在机器学习和深度学习领域中，尤其是自然语言处理和计算机视觉等领域，参数数量非常庞大的模型。这类模型通常使用深度神经...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/12/31/Langchain%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="LangChain学习笔记"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-31</div><div class="info-item-2">LangChain学习笔记</div></div><div class="info-2"><div class="info-item-1"> 01-LangChain使用概述  </div></div></div></a><a class="pagination-related" href="/2026/01/09/langchain-helloworld/" title="LangChain-HelloWorld"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-09</div><div class="info-item-2">LangChain-HelloWorld</div></div><div class="info-2"><div class="info-item-1">1. 获取大模型12345678910111213141516171819#导入 dotenv 库的 load_dotenv 函数，用于加载环境变量文件（.env）中的配置import dotenvfrom langchain_openai import ChatOpenAIimport os# 加载环境变量文件dotenv.load_dotenv()# 获取open-ai的api密钥os.environ[&#x27;OPENAI_API_KEY&#x27;] = os.getenv(&#x27;OPENAI_API_KEY&#x27;)# 创建 ChatOpenAI 对象llm = ChatOpenAI(model=&quot;gpt-4o-mini&quot;)# 直接提供问题，并调用llmresponse = llm.invoke(&quot;什么是大模型？&quot;)# 打印结果print(response)  content=&#39;“大模型”通常指的是在机器学习和深度学习领域中，尤其是自然语言处理和计算机视觉等领域，参数数量非常庞大的模型。这类模型通常使用深度神经...</div></div></div></a><a class="pagination-related" href="/2025/12/30/Langchain%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/" title="LangChain快速上手"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-30</div><div class="info-item-2">LangChain快速上手</div></div><div class="info-2"><div class="info-item-1">1. 创建虚拟环境这里我采用的是 conda 环境： 12345# 创建名为 langchain-env 的新环境（使用 Python 3.10）conda create -n langchain-env python=3.10 -y# 激活环境conda activate langchain-env 2. 安装LangChain以及相关依赖123456# 安装 langchain 核心包pip install langchain# 安装常用的组件（例如 OpenAI、本地 LLM 支持、文档加载器等）pip install langchain-openai  # 如果你打算用 OpenAIpip install python-dotenv     # 用于管理 API 密钥 3. 基于open-ai模型的入门程序3.1 设置 API 密钥新建一个langchain_demo项目 在项目根目录中新建.env文件 1touch .env  编辑 .env 文件，填入 OpenAI API Key： 1OPENAI_API_KEY=openai-api-key-here  从 Ope...</div></div></div></a><a class="pagination-related" href="/2025/12/28/Ollama%E9%83%A8%E7%BD%B2qwen:7b/" title="Ollama部署qwen:7b"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-28</div><div class="info-item-2">Ollama部署qwen:7b</div></div><div class="info-2"><div class="info-item-1">1. 安装OllamaLinux上安装可以直接运行一下命令： 1curl -fsSL https://ollama.com/install.sh | sh MacOS经过试验，推荐还是老老实实去官网下载dmg安装文件。。。https://ollama.com 测试安装是否成功 1ollama --version 2. Ollama基础命令2.1 拉取模型1ollama pull &lt;model-name&gt; 2.2 列出本地模型1ollama list 2.3 删除模型1olllama rm &lt;model-name&gt; 2.4 复制模型（重命名）1ollama cp &lt;model-name&gt; &lt;model-other-name&gt; 2.5 启动交互式对话1ollama run &lt;model-name&gt; 进入后可直接输入问题，输入 &#x2F;bye 或 Ctrl+D 退出。 2.6 一次性推理1echo &quot;写一首关于春天的诗&quot; | ollama run &lt;model-name&gt; 2.7 停止服务1...</div></div></div></a><a class="pagination-related" href="/2025/12/29/Dify%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/" title="Dify快速上手"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-29</div><div class="info-item-2">Dify快速上手</div></div><div class="info-2"><div class="info-item-1"> Dify 是一个开源的 LLM 应用开发平台，支持通过可视化界面或 API 快速构建基于大语言模型（如 Qwen、Llama、GPT 等）的 AI 应用（如智能客服、知识库问答、Agent 工作流等）。  1. 安装Dify前置条件  确保 Ollama 正在运行（终端执行 ollama run qwen:7b 测试过） 终端可访问 docker 命令  1.1 克隆Dify仓库12git clone https://github.com/langgenius/dify.gitcd dify 1.2 复制环境配置1cp .env.example .env 一般不需要修改 1.3 Docker构建1docker compose up -d 1.4 访问界面http://localhost/install 2. 在 Dify 中接入本地 Qwen（通过Ollama）进入界面 右侧设置-&gt;模型供应商 点击 + Add Model Provider 选择 Ollama 填写：Base URL: http://host.docker.internal:11434 ✅ 这是 Dock...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="https://github.com/muzicoding/muzicoding-img/blob/master/avatar/avatar.png?raw=true" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Muzi</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">15</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/muzicoding"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/muzicoding" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:xpli0129@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Model-I-O%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">1. Model I&#x2F;O介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Model-I-O%E4%B9%8B%E8%B0%83%E7%94%A8%E6%A8%A1%E5%9E%8B1"><span class="toc-number">2.</span> <span class="toc-text">2. Model I&#x2F;O之调用模型1</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-LLMs-%E9%9D%9E%E5%AF%B9%E8%AF%9D%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 LLMs(非对话模型)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Chat-Models-%E5%AF%B9%E8%AF%9D%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 Chat Models(对话模型)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-Embedding-Model-%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 Embedding Model(嵌入模型)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Model-I-O%E4%B9%8B%E8%B0%83%E7%94%A8%E6%A8%A1%E5%9E%8B2"><span class="toc-number">3.</span> <span class="toc-text">3. Model I&#x2F;O之调用模型2</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%85%B3%E4%BA%8E%E5%AF%B9%E8%AF%9D%E6%A8%A1%E5%9E%8B%E7%9A%84Message-%E6%B6%88%E6%81%AF"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 关于对话模型的Message(消息)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E5%85%B3%E4%BA%8E%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AE%B0%E5%BF%86"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 关于多轮对话与上下文记忆</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E5%85%B3%E4%BA%8E%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">3.3.</span> <span class="toc-text">3.3 关于模型调用的方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-1-%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA%E4%B8%8E%E9%9D%9E%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA"><span class="toc-number">3.3.1.</span> <span class="toc-text">3.3.1 流式输出与非流式输出</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-3-%E5%90%8C%E6%AD%A5%E8%B0%83%E7%94%A8%E4%B8%8E%E5%BC%82%E6%AD%A5%E8%B0%83%E7%94%A8-%E4%BA%86%E8%A7%A3"><span class="toc-number">3.3.2.</span> <span class="toc-text">3.3.3 同步调用与异步调用(了解)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Model-I-O%E4%B9%8BPrompt-Template"><span class="toc-number">4.</span> <span class="toc-text">4. Model I&#x2F;O之Prompt Template</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E5%85%B7%E4%BD%93%E4%BD%BF%E7%94%A8%EF%BC%9APromptTemplate"><span class="toc-number">4.1.</span> <span class="toc-text">4.3 具体使用：PromptTemplate</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-2-%E4%B8%A4%E7%A7%8D%E5%AE%9E%E4%BE%8B%E5%8C%96%E6%96%B9%E5%BC%8F"><span class="toc-number">4.1.1.</span> <span class="toc-text">4.3.2 两种实例化方式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-3-%E4%B8%A4%E7%A7%8D%E6%96%B0%E7%9A%84%E7%BB%93%E6%9E%84%E5%BD%A2%E5%BC%8F"><span class="toc-number">4.1.2.</span> <span class="toc-text">4.3.3 两种新的结构形式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-4-format-%E4%B8%8E-invoke"><span class="toc-number">4.1.3.</span> <span class="toc-text">4.3.4 format() 与 invoke()</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-5-%E7%BB%93%E5%90%88LLM%E8%B0%83%E7%94%A8"><span class="toc-number">4.1.4.</span> <span class="toc-text">4.3.5 结合LLM调用</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E5%85%B7%E4%BD%93%E4%BD%BF%E7%94%A8%EF%BC%9AChatPromptTemplate"><span class="toc-number">4.2.</span> <span class="toc-text">4.4 具体使用：ChatPromptTemplate</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-2-%E4%B8%A4%E7%A7%8D%E5%AE%9E%E4%BE%8B%E5%8C%96%E6%96%B9%E5%BC%8F"><span class="toc-number">4.2.1.</span> <span class="toc-text">4.4.2 两种实例化方式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-3-%E6%A8%A1%E6%9D%BF%E8%B0%83%E7%94%A8%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F"><span class="toc-number">4.2.2.</span> <span class="toc-text">4.4.3 模板调用的几种方式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-4-%E7%BB%93%E5%90%88LLM"><span class="toc-number">4.2.3.</span> <span class="toc-text">4.4.4 结合LLM</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-6-%E6%8F%92%E5%85%A5%E6%B6%88%E6%81%AF%E5%88%97%E8%A1%A8%EF%BC%9AMessagesPlaceholder"><span class="toc-number">4.2.4.</span> <span class="toc-text">4.4.6 插入消息列表：MessagesPlaceholder</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%E5%85%B7%E4%BD%93%E4%BD%BF%E7%94%A8%EF%BC%9A%E5%B0%91%E9%87%8F%E6%A0%B7%E6%9C%AC%E7%A4%BA%E4%BE%8B%E7%9A%84%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%A8%A1%E6%9D%BF"><span class="toc-number">4.3.</span> <span class="toc-text">4.5 具体使用：少量样本示例的提示词模板</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-5-2-FewShotPromptTemplate%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">4.3.1.</span> <span class="toc-text">4.5.2 FewShotPromptTemplate的使用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-5-3-FewShotChatMessagePromptTemplate%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">4.3.2.</span> <span class="toc-text">4.5.3 FewShotChatMessagePromptTemplate的使用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-5-4-Example-selectors-%E7%A4%BA%E4%BE%8B%E9%80%89%E6%8B%A9%E5%99%A8"><span class="toc-number">4.3.3.</span> <span class="toc-text">4.5.4 Example selectors(示例选择器)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5%E3%80%81Model-I-O%E4%B9%8BOutput-Parsers"><span class="toc-number">5.</span> <span class="toc-text">5、Model I&#x2F;O之Output Parsers</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E8%BE%93%E5%87%BA%E8%A7%A3%E6%9E%90%E5%99%A8%E7%9A%84%E5%88%86%E7%B1%BB"><span class="toc-number">5.1.</span> <span class="toc-text">5.1 输出解析器的分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E5%85%B7%E4%BD%93%E8%A7%A3%E6%9E%90%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">5.2.</span> <span class="toc-text">5.2 具体解析器的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-1%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%A7%A3%E6%9E%90%E5%99%A8-StrOutputParser"><span class="toc-number">5.2.1.</span> <span class="toc-text">5.2.1字符串解析器 StrOutputParser</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-2-JSON%E8%A7%A3%E6%9E%90%E5%99%A8-JsonOutputParser"><span class="toc-number">5.2.2.</span> <span class="toc-text">5.2.2 JSON解析器 JsonOutputParser</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-3-XML%E8%A7%A3%E6%9E%90%E5%99%A8-XMLOutputParser"><span class="toc-number">5.2.3.</span> <span class="toc-text">5.2.3 XML解析器 XMLOutputParser</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-4-%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%99%A8-CommaSeparatedListOutputParser"><span class="toc-number">5.2.4.</span> <span class="toc-text">5.2.4 列表解析器 CommaSeparatedListOutputParser</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%A5%E6%9C%9F%E8%A7%A3%E6%9E%90%E5%99%A8-DatetimeOutputParser-%E4%BA%86%E8%A7%A3"><span class="toc-number">5.2.5.</span> <span class="toc-text">日期解析器 DatetimeOutputParser (了解)</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/10/langchain-model-io/" title="LangChain使用之Model I/O">LangChain使用之Model I/O</a><time datetime="2026-01-09T16:00:00.000Z" title="发表于 2026-01-10 00:00:00">2026-01-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/09/langchain-helloworld/" title="LangChain-HelloWorld">LangChain-HelloWorld</a><time datetime="2026-01-08T16:00:00.000Z" title="发表于 2026-01-09 00:00:00">2026-01-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/31/Langchain%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="LangChain学习笔记">LangChain学习笔记</a><time datetime="2025-12-30T16:00:00.000Z" title="发表于 2025-12-31 00:00:00">2025-12-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/30/Langchain%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/" title="LangChain快速上手">LangChain快速上手</a><time datetime="2025-12-29T16:00:00.000Z" title="发表于 2025-12-30 00:00:00">2025-12-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/29/Dify%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/" title="Dify快速上手">Dify快速上手</a><time datetime="2025-12-28T16:00:00.000Z" title="发表于 2025-12-29 00:00:00">2025-12-29</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://github.com/muzicoding/muzicoding-img/blob/master/footer_img/background.jpeg?raw=true);"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By Muzi</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.3"></script><script src="/js/main.js?v=5.5.3"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>